{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm  \n",
    "from dataloader import *\n",
    "from model import * \n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import nltk \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "target_confidence = 0.8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs, labels = zip(*batch)\n",
    "    max_length = max(len(seq) for seq in inputs)\n",
    "    \n",
    "    # Convert each sequence to a list, pad with 0, and convert to tensor\n",
    "    padded_inputs = [torch.cat([seq, torch.zeros(max_length - len(seq), dtype=torch.long)]) for seq in inputs]\n",
    "    lengths = [len(seq) for seq in inputs]\n",
    "    \n",
    "    return torch.stack(padded_inputs), torch.tensor(labels, dtype=torch.float), lengths\n",
    "\n",
    "def tokens_to_words(token_ids, vocab):\n",
    "    inv_vocab = {v: k for k, v in vocab.items()}\n",
    "    return [inv_vocab.get(token_id, '<UNK>') for token_id in token_ids if token_id != 0]  # Exclude padding\n",
    "\n",
    "\n",
    "class TextDatasetTest(Dataset):\n",
    "    def __init__(self, data_dir, vocab, files):\n",
    "        super(TextDatasetTest, self).__init__()\n",
    "        self.data = []\n",
    "        self.vocab = vocab \n",
    "\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(data_dir, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    tokens = line.strip().split()\n",
    "                    label = 1 if filename.endswith('.1') else 0  # Binary label\n",
    "                    self.data.append((tokens, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens, label = self.data[idx]\n",
    "        token_ids = [self.vocab.get(token, self.vocab['<UNK>']) for token in tokens]\n",
    "        return torch.tensor(token_ids, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
    "     \n",
    "    \n",
    "files = [\"sentiment.train.0\", \"sentiment.train.1\"]\n",
    "files_test = [\"sentiment.test.0\", \"sentiment.test.1\"]\n",
    "\n",
    "data_dir = \"./data/sentiment_style_transfer/yelp\"\n",
    "vocab = build_vocab(data_dir)\n",
    "dataset = TextDatasetTest(data_dir, vocab, files)\n",
    "dataset_test = TextDatasetTest(data_dir, vocab, files_test)\n",
    "data_loader = DataLoader(dataset, batch_size=64, collate_fn=collate_fn, shuffle=True)\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=64, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443259"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisentangledVAE(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, style_dim, content_dim):\n",
    "        super(DisentangledVAE, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder_rnn = nn.GRU(embedding_dim, hidden_dim, \n",
    "                                 batch_first=True, \n",
    "                                 bidirectional=True,\n",
    "                                 num_layers=2,\n",
    "                                 dropout=0.2)\n",
    "        \n",
    "        # Latent spaces\n",
    "        self.style_encoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.content_encoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        # Mean and logvar projections\n",
    "        self.style_mu = nn.Linear(hidden_dim, style_dim)\n",
    "        self.style_logvar = nn.Linear(hidden_dim, style_dim)\n",
    "        self.content_mu = nn.Linear(hidden_dim, content_dim)\n",
    "        self.content_logvar = nn.Linear(hidden_dim, content_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.latent_to_hidden = nn.Sequential(\n",
    "            nn.Linear(style_dim + content_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        self.decoder_rnn = nn.GRU(embedding_dim + hidden_dim, hidden_dim,\n",
    "                                 batch_first=True,\n",
    "                                 num_layers=2,\n",
    "                                 dropout=0.2)\n",
    "        \n",
    "        self.output_fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "        # Style classifier for adversarial training\n",
    "        self.style_classifier = nn.Sequential(\n",
    "            nn.Linear(style_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def encode(self, x, lengths=None):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Embed input\n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        # Pack for variable length sequences\n",
    "        if lengths is not None:\n",
    "            embedded = nn.utils.rnn.pack_padded_sequence(\n",
    "                embedded, lengths, batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "        \n",
    "        # Encode\n",
    "        _, hidden = self.encoder_rnn(embedded)\n",
    "        # Combine bidirectional states\n",
    "        hidden = torch.cat([hidden[-2], hidden[-1]], dim=1)\n",
    "        \n",
    "        # Encode style and content\n",
    "        style_hidden = self.style_encoder(hidden)\n",
    "        content_hidden = self.content_encoder(hidden)\n",
    "        \n",
    "        # Get latent parameters\n",
    "        style_mu = self.style_mu(style_hidden)\n",
    "        style_logvar = self.style_logvar(style_hidden)\n",
    "        content_mu = self.content_mu(content_hidden)\n",
    "        content_logvar = self.content_logvar(content_hidden)\n",
    "        \n",
    "        return style_mu, style_logvar, content_mu, content_logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "        \n",
    "    def decode(self, style, content, x):\n",
    "        batch_size = x.size(0)\n",
    "        max_len = x.size(1)\n",
    "        \n",
    "        # Combine latent vectors\n",
    "        latent = torch.cat([style, content], dim=1)\n",
    "        hidden = self.latent_to_hidden(latent)\n",
    "        \n",
    "        # Initialize decoder hidden state\n",
    "        hidden = hidden.unsqueeze(0).repeat(2, 1, 1)  # num_layers * batch * hidden\n",
    "        \n",
    "        # Teacher forcing with concatenated latent\n",
    "        embedded = self.embedding(x)\n",
    "        hidden_expanded = hidden[-1].unsqueeze(1).repeat(1, max_len, 1)\n",
    "        decoder_input = torch.cat([embedded, hidden_expanded], dim=2)\n",
    "        \n",
    "        # Decode\n",
    "        outputs, _ = self.decoder_rnn(decoder_input, hidden)\n",
    "        outputs = self.output_fc(outputs)\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x, lengths=None):\n",
    "        # Encode\n",
    "        style_mu, style_logvar, content_mu, content_logvar = self.encode(x, lengths)\n",
    "        \n",
    "        # Sample latent vectors\n",
    "        style = self.reparameterize(style_mu, style_logvar)\n",
    "        content = self.reparameterize(content_mu, content_logvar)\n",
    "        \n",
    "        # Decode\n",
    "        recon_x = self.decode(style, content, x)\n",
    "        \n",
    "        return recon_x, style_mu, style_logvar, content_mu, content_logvar, style, content\n",
    "\n",
    "    def classify_style(self, style):\n",
    "        return self.style_classifier(style)\n",
    "\n",
    "def vae_loss(recon_x, x, style_mu, style_logvar, content_mu, content_logvar):\n",
    "    recon_loss = F.cross_entropy(recon_x.view(-1, recon_x.size(-1)), x.view(-1), ignore_index=0)  # Reconstruction loss\n",
    "    kl_style = -0.5 * torch.sum(1 + style_logvar - style_mu.pow(2) - style_logvar.exp())  # KL divergence for style\n",
    "    kl_content = -0.5 * torch.sum(1 + content_logvar - content_mu.pow(2) - content_logvar.exp())  # KL divergence for content\n",
    "    return recon_loss + kl_style + kl_content\n",
    "\n",
    "def multi_task_loss(style_preds, style_labels, content_preds, content_labels):\n",
    "    style_loss = F.cross_entropy(style_preds, style_labels)  # Style classification loss\n",
    "    content_loss = F.cross_entropy(content_preds, content_labels)  # Content classification loss\n",
    "    return style_loss + content_loss\n",
    "\n",
    "def adversarial_loss(style_preds, content_preds):\n",
    "    adversarial_style_loss = -F.cross_entropy(style_preds, torch.zeros_like(style_preds))  # Fool style classifier\n",
    "    adversarial_content_loss = -F.cross_entropy(content_preds, torch.zeros_like(content_preds))  # Fool content classifier\n",
    "    return adversarial_style_loss + adversarial_content_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6926"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 10 epochs...\n",
      "\n",
      "Epoch 1/10\n",
      "--------------------------------------------------\n",
      "\n",
      "Training on 443259 examples with 6926 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 9/6926 [00:00<01:17, 89.28it/s, batch_loss=7.0265]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First batch shapes:\n",
      "Input tokens: torch.Size([64, 15])\n",
      "Style labels: torch.Size([64])\n",
      "Sequence lengths: [6, 6, 11, 2, 7] (showing first 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 116/6926 [00:01<01:08, 99.26it/s, batch_loss=2.5323]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 100/6926\n",
      "Reconstruction Loss: 2.4905\n",
      "KL Loss: 0.1018\n",
      "Style Loss: 0.6910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 213/6926 [00:02<01:06, 100.41it/s, batch_loss=1.6083]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 200/6926\n",
      "Reconstruction Loss: 0.8596\n",
      "KL Loss: 0.0078\n",
      "Style Loss: 0.7021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 312/6926 [00:03<01:05, 100.59it/s, batch_loss=1.1687]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 300/6926\n",
      "Reconstruction Loss: 0.7121\n",
      "KL Loss: 0.0003\n",
      "Style Loss: 0.6962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 420/6926 [00:04<01:04, 100.34it/s, batch_loss=1.0416]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 400/6926\n",
      "Reconstruction Loss: 0.4625\n",
      "KL Loss: 0.0003\n",
      "Style Loss: 0.6734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 517/6926 [00:05<01:07, 95.04it/s, batch_loss=1.1454] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 500/6926\n",
      "Reconstruction Loss: 0.3419\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 618/6926 [00:06<01:04, 98.32it/s, batch_loss=0.9942]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 600/6926\n",
      "Reconstruction Loss: 0.2787\n",
      "KL Loss: 0.7205\n",
      "Style Loss: 0.7437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 720/6926 [00:07<01:02, 99.53it/s, batch_loss=0.7953]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 700/6926\n",
      "Reconstruction Loss: 0.2321\n",
      "KL Loss: 0.0372\n",
      "Style Loss: 0.6939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 817/6926 [00:08<01:00, 101.01it/s, batch_loss=0.9279]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 800/6926\n",
      "Reconstruction Loss: 0.2377\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 916/6926 [00:09<00:58, 103.35it/s, batch_loss=0.8242]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 900/6926\n",
      "Reconstruction Loss: 0.1149\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 1015/6926 [00:10<00:57, 103.30it/s, batch_loss=0.8207]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1000/6926\n",
      "Reconstruction Loss: 0.1388\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.7283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 1112/6926 [00:11<00:55, 104.75it/s, batch_loss=0.7217]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1100/6926\n",
      "Reconstruction Loss: 0.1023\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 1211/6926 [00:12<00:54, 104.15it/s, batch_loss=0.7705]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1200/6926\n",
      "Reconstruction Loss: 0.0735\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 1310/6926 [00:13<00:53, 104.74it/s, batch_loss=0.7479]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1300/6926\n",
      "Reconstruction Loss: 0.0721\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 1420/6926 [00:14<00:52, 105.12it/s, batch_loss=0.7667]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1400/6926\n",
      "Reconstruction Loss: 0.0480\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 1519/6926 [00:14<00:51, 104.55it/s, batch_loss=0.7451]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1500/6926\n",
      "Reconstruction Loss: 0.0419\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 1618/6926 [00:15<00:50, 104.76it/s, batch_loss=0.7922]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1600/6926\n",
      "Reconstruction Loss: 0.1596\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 1717/6926 [00:16<00:50, 103.08it/s, batch_loss=0.7108]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1700/6926\n",
      "Reconstruction Loss: 0.0425\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 1816/6926 [00:17<00:48, 105.45it/s, batch_loss=0.7470]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1800/6926\n",
      "Reconstruction Loss: 0.0614\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 1915/6926 [00:18<00:49, 101.82it/s, batch_loss=0.6818]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1900/6926\n",
      "Reconstruction Loss: 0.0269\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.7194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|██▉       | 2013/6926 [00:19<00:47, 103.24it/s, batch_loss=0.6845]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2000/6926\n",
      "Reconstruction Loss: 0.0484\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 2111/6926 [00:20<00:48, 98.45it/s, batch_loss=0.7068] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2100/6926\n",
      "Reconstruction Loss: 0.0384\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|███▏      | 2220/6926 [00:21<00:46, 101.04it/s, batch_loss=0.6968]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2200/6926\n",
      "Reconstruction Loss: 0.0294\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|███▎      | 2317/6926 [00:22<00:45, 101.74it/s, batch_loss=0.6972]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2300/6926\n",
      "Reconstruction Loss: 0.0360\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▍      | 2411/6926 [00:23<00:45, 99.44it/s, batch_loss=0.7074] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2400/6926\n",
      "Reconstruction Loss: 0.0476\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|███▋      | 2515/6926 [00:24<00:44, 99.40it/s, batch_loss=0.6774]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2500/6926\n",
      "Reconstruction Loss: 0.0074\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 2614/6926 [00:25<00:43, 100.21it/s, batch_loss=0.6761]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2600/6926\n",
      "Reconstruction Loss: 0.0092\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███▉      | 2712/6926 [00:26<00:42, 98.19it/s, batch_loss=0.7229] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2700/6926\n",
      "Reconstruction Loss: 0.0101\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|████      | 2815/6926 [00:27<00:41, 99.86it/s, batch_loss=0.6991] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2800/6926\n",
      "Reconstruction Loss: 0.0021\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|████▏     | 2912/6926 [00:28<00:40, 99.58it/s, batch_loss=0.6008] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2900/6926\n",
      "Reconstruction Loss: 0.0421\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|████▎     | 3014/6926 [00:29<00:39, 98.37it/s, batch_loss=0.6881]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3000/6926\n",
      "Reconstruction Loss: 0.0062\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▌     | 3120/6926 [00:30<00:37, 100.19it/s, batch_loss=0.7028]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3100/6926\n",
      "Reconstruction Loss: 0.0029\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|████▋     | 3219/6926 [00:31<00:37, 99.98it/s, batch_loss=0.7133] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3200/6926\n",
      "Reconstruction Loss: 0.0015\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|████▊     | 3314/6926 [00:32<00:36, 99.16it/s, batch_loss=0.6696] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3300/6926\n",
      "Reconstruction Loss: 0.0052\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|████▉     | 3411/6926 [00:33<00:35, 98.54it/s, batch_loss=0.6886] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3400/6926\n",
      "Reconstruction Loss: 0.0042\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  51%|█████     | 3517/6926 [00:34<00:34, 99.90it/s, batch_loss=0.6585]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3500/6926\n",
      "Reconstruction Loss: 0.0013\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|█████▏    | 3618/6926 [00:35<00:33, 99.00it/s, batch_loss=0.6665]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3600/6926\n",
      "Reconstruction Loss: 0.0018\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|█████▎    | 3710/6926 [00:36<00:32, 99.63it/s, batch_loss=0.7045]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3700/6926\n",
      "Reconstruction Loss: 0.0021\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 3820/6926 [00:37<00:30, 100.48it/s, batch_loss=0.7250]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3800/6926\n",
      "Reconstruction Loss: 0.0018\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 3918/6926 [00:38<00:30, 100.15it/s, batch_loss=0.6848]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3900/6926\n",
      "Reconstruction Loss: 0.0058\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.7232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|█████▊    | 4016/6926 [00:39<00:29, 98.76it/s, batch_loss=0.6778] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4000/6926\n",
      "Reconstruction Loss: 0.0014\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|█████▉    | 4115/6926 [00:40<00:28, 100.04it/s, batch_loss=0.6901]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4100/6926\n",
      "Reconstruction Loss: 0.0045\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|██████    | 4214/6926 [00:41<00:26, 100.72it/s, batch_loss=0.6308]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4200/6926\n",
      "Reconstruction Loss: 0.0017\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|██████▏   | 4310/6926 [00:42<00:26, 100.15it/s, batch_loss=0.6581]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4300/6926\n",
      "Reconstruction Loss: 0.0066\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|██████▍   | 4420/6926 [00:43<00:24, 100.43it/s, batch_loss=0.6730]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4400/6926\n",
      "Reconstruction Loss: 0.0010\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 4518/6926 [00:44<00:24, 100.25it/s, batch_loss=0.6050]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4500/6926\n",
      "Reconstruction Loss: 0.0013\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|██████▋   | 4617/6926 [00:45<00:22, 100.53it/s, batch_loss=0.6634]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4600/6926\n",
      "Reconstruction Loss: 0.0007\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.7141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|██████▊   | 4715/6926 [00:46<00:22, 100.14it/s, batch_loss=0.6989]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4700/6926\n",
      "Reconstruction Loss: 0.0118\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|██████▉   | 4812/6926 [00:47<00:21, 99.93it/s, batch_loss=0.6846] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4800/6926\n",
      "Reconstruction Loss: 0.0010\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 4911/6926 [00:48<00:20, 100.15it/s, batch_loss=0.6866]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4900/6926\n",
      "Reconstruction Loss: 0.0006\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|███████▏  | 5018/6926 [00:49<00:18, 100.51it/s, batch_loss=0.6747]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5000/6926\n",
      "Reconstruction Loss: 0.0006\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████▍  | 5115/6926 [00:50<00:18, 99.86it/s, batch_loss=0.7375] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5100/6926\n",
      "Reconstruction Loss: 0.0008\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 5211/6926 [00:51<00:17, 99.95it/s, batch_loss=0.6648] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5200/6926\n",
      "Reconstruction Loss: 0.0010\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|███████▋  | 5320/6926 [00:52<00:15, 101.00it/s, batch_loss=0.7029]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5300/6926\n",
      "Reconstruction Loss: 0.0006\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|███████▊  | 5417/6926 [00:53<00:15, 99.39it/s, batch_loss=0.6786] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5400/6926\n",
      "Reconstruction Loss: 0.0006\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|███████▉  | 5516/6926 [00:54<00:14, 100.16it/s, batch_loss=0.6748]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5500/6926\n",
      "Reconstruction Loss: 0.0003\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  81%|████████  | 5615/6926 [00:55<00:12, 100.85it/s, batch_loss=0.6896]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5600/6926\n",
      "Reconstruction Loss: 0.0005\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%|████████▏ | 5712/6926 [00:56<00:12, 98.71it/s, batch_loss=0.6738] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5700/6926\n",
      "Reconstruction Loss: 0.0006\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  84%|████████▍ | 5811/6926 [00:57<00:11, 100.94it/s, batch_loss=0.6433]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5800/6926\n",
      "Reconstruction Loss: 0.0004\n",
      "KL Loss: 0.0004\n",
      "Style Loss: 0.7041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 5910/6926 [00:58<00:10, 100.66it/s, batch_loss=0.6844]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5900/6926\n",
      "Reconstruction Loss: 0.0007\n",
      "KL Loss: -0.0000\n",
      "Style Loss: 0.6629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  87%|████████▋ | 6020/6926 [00:59<00:08, 100.85it/s, batch_loss=0.6264]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6000/6926\n",
      "Reconstruction Loss: 0.0005\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████▊ | 6119/6926 [01:00<00:07, 101.49it/s, batch_loss=0.6730]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6100/6926\n",
      "Reconstruction Loss: 0.0004\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|████████▉ | 6218/6926 [01:01<00:06, 102.11it/s, batch_loss=0.7037]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6200/6926\n",
      "Reconstruction Loss: 0.0087\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  91%|█████████ | 6317/6926 [01:02<00:05, 101.90it/s, batch_loss=0.6822]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6300/6926\n",
      "Reconstruction Loss: 0.0004\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  93%|█████████▎| 6416/6926 [01:03<00:05, 100.57it/s, batch_loss=0.6679]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6400/6926\n",
      "Reconstruction Loss: 0.0003\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 6515/6926 [01:04<00:04, 101.86it/s, batch_loss=0.6426]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6500/6926\n",
      "Reconstruction Loss: 0.0004\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|█████████▌| 6614/6926 [01:05<00:03, 101.65it/s, batch_loss=0.6804]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6600/6926\n",
      "Reconstruction Loss: 0.0002\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|█████████▋| 6713/6926 [01:06<00:02, 100.42it/s, batch_loss=0.7161]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6700/6926\n",
      "Reconstruction Loss: 0.0004\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████▊| 6812/6926 [01:07<00:01, 101.50it/s, batch_loss=0.7052]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6800/6926\n",
      "Reconstruction Loss: 0.0002\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████▉| 6911/6926 [01:08<00:00, 99.60it/s, batch_loss=0.6599] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6900/6926\n",
      "Reconstruction Loss: 0.0008\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 6926/6926 [01:08<00:00, 100.71it/s, batch_loss=0.6927]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed epoch. Average loss: 0.8246\n",
      "Epoch 1/10, Loss: 0.8246\n",
      "\n",
      "Epoch 2/10\n",
      "--------------------------------------------------\n",
      "\n",
      "Training on 443259 examples with 6926 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 10/6926 [00:00<01:14, 92.86it/s, batch_loss=0.6487]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First batch shapes:\n",
      "Input tokens: torch.Size([64, 14])\n",
      "Style labels: torch.Size([64])\n",
      "Sequence lengths: [7, 7, 14, 8, 8] (showing first 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 120/6926 [00:01<01:07, 100.93it/s, batch_loss=0.6426]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 100/6926\n",
      "Reconstruction Loss: 0.0002\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 219/6926 [00:02<01:06, 101.54it/s, batch_loss=0.6428]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 200/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 318/6926 [00:03<01:04, 101.72it/s, batch_loss=0.6945]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 300/6926\n",
      "Reconstruction Loss: 0.0003\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 417/6926 [00:04<01:04, 101.68it/s, batch_loss=0.6565]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 400/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 516/6926 [00:05<01:03, 101.19it/s, batch_loss=0.6437]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 500/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 615/6926 [00:06<01:02, 100.43it/s, batch_loss=0.6944]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 600/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 714/6926 [00:07<01:01, 100.69it/s, batch_loss=0.7168]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 700/6926\n",
      "Reconstruction Loss: 0.0002\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 813/6926 [00:08<01:01, 100.09it/s, batch_loss=0.7244]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 800/6926\n",
      "Reconstruction Loss: 0.0002\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 912/6926 [00:09<01:00, 100.15it/s, batch_loss=0.6856]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 900/6926\n",
      "Reconstruction Loss: 0.0002\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.7108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 1011/6926 [00:10<00:58, 101.58it/s, batch_loss=0.6458]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1000/6926\n",
      "Reconstruction Loss: 0.0002\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 1110/6926 [00:11<00:57, 101.87it/s, batch_loss=0.6455]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1100/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 1220/6926 [00:12<00:56, 101.70it/s, batch_loss=0.6731]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1200/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 1319/6926 [00:13<00:55, 101.45it/s, batch_loss=0.6615]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1300/6926\n",
      "Reconstruction Loss: 0.0002\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 1418/6926 [00:14<00:54, 101.97it/s, batch_loss=0.6712]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1400/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 1517/6926 [00:15<00:53, 101.12it/s, batch_loss=0.6534]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1500/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 1616/6926 [00:16<00:51, 102.24it/s, batch_loss=0.7122]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1600/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 1715/6926 [00:16<00:50, 102.54it/s, batch_loss=0.6157]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1700/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 1814/6926 [00:17<00:50, 102.00it/s, batch_loss=0.6886]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1800/6926\n",
      "Reconstruction Loss: 0.0003\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 1913/6926 [00:18<00:49, 101.52it/s, batch_loss=0.6963]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1900/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|██▉       | 2012/6926 [00:19<00:48, 102.10it/s, batch_loss=0.6960]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2000/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0003\n",
      "Style Loss: 0.6820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 2111/6926 [00:20<00:47, 101.84it/s, batch_loss=0.6939]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2100/6926\n",
      "Reconstruction Loss: 0.0141\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|███▏      | 2210/6926 [00:21<00:46, 100.77it/s, batch_loss=0.6852]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2200/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|███▎      | 2320/6926 [00:22<00:45, 101.38it/s, batch_loss=0.6708]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2300/6926\n",
      "Reconstruction Loss: 0.0002\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▍      | 2419/6926 [00:23<00:44, 101.54it/s, batch_loss=0.6535]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2400/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|███▋      | 2518/6926 [00:24<00:43, 101.06it/s, batch_loss=0.6607]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2500/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 2617/6926 [00:25<00:42, 101.63it/s, batch_loss=0.7062]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2600/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███▉      | 2716/6926 [00:26<00:41, 100.45it/s, batch_loss=0.7030]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2700/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|████      | 2815/6926 [00:27<00:41, 100.26it/s, batch_loss=0.6859]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2800/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|████▏     | 2912/6926 [00:28<00:40, 99.89it/s, batch_loss=0.6678] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2900/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0003\n",
      "Style Loss: 0.6380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|████▎     | 3020/6926 [00:29<00:39, 100.12it/s, batch_loss=0.5979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3000/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▌     | 3119/6926 [00:30<00:37, 101.76it/s, batch_loss=0.6714]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|████▋     | 3216/6926 [00:31<00:37, 98.97it/s, batch_loss=0.6628] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|████▊     | 3314/6926 [00:32<00:36, 100.07it/s, batch_loss=0.6533]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.7120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|████▉     | 3419/6926 [00:33<00:35, 97.69it/s, batch_loss=0.6879] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  51%|█████     | 3517/6926 [00:34<00:33, 101.06it/s, batch_loss=0.6292]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3500/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|█████▏    | 3616/6926 [00:35<00:32, 102.22it/s, batch_loss=0.6663]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3600/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|█████▎    | 3715/6926 [00:36<00:32, 100.18it/s, batch_loss=0.7161]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3700/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 3811/6926 [00:37<00:31, 97.46it/s, batch_loss=0.6515] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▋    | 3913/6926 [00:38<00:30, 97.92it/s, batch_loss=0.6604]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3900/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|█████▊    | 4019/6926 [00:39<00:29, 99.15it/s, batch_loss=0.6666] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|█████▉    | 4112/6926 [00:40<00:28, 100.46it/s, batch_loss=0.6959]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|██████    | 4216/6926 [00:41<00:27, 98.45it/s, batch_loss=0.6535] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|██████▏   | 4319/6926 [00:42<00:26, 99.37it/s, batch_loss=0.6600]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|██████▎   | 4413/6926 [00:43<00:25, 99.46it/s, batch_loss=0.6293] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 4516/6926 [00:44<00:24, 98.41it/s, batch_loss=0.6777]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4500/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|██████▋   | 4618/6926 [00:45<00:23, 98.13it/s, batch_loss=0.6838]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4600/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|██████▊   | 4710/6926 [00:46<00:22, 98.61it/s, batch_loss=0.6559]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4700/6926\n",
      "Reconstruction Loss: 0.0018\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|██████▉   | 4814/6926 [00:47<00:21, 99.99it/s, batch_loss=0.6461]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 4913/6926 [00:48<00:19, 101.79it/s, batch_loss=0.6707]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|███████▏  | 5012/6926 [00:49<00:18, 101.81it/s, batch_loss=0.6916]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5000/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████▍  | 5111/6926 [00:50<00:18, 100.18it/s, batch_loss=0.6244]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 5210/6926 [00:51<00:16, 102.07it/s, batch_loss=0.6564]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|███████▋  | 5320/6926 [00:52<00:15, 101.25it/s, batch_loss=0.6732]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|███████▊  | 5415/6926 [00:53<00:15, 99.69it/s, batch_loss=0.6698] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|███████▉  | 5519/6926 [00:54<00:14, 100.22it/s, batch_loss=0.6098]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  81%|████████  | 5618/6926 [00:55<00:12, 101.58it/s, batch_loss=0.6798]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|████████▎ | 5717/6926 [00:56<00:11, 101.26it/s, batch_loss=0.6722]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  84%|████████▍ | 5816/6926 [00:57<00:11, 99.75it/s, batch_loss=0.7227] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 5913/6926 [00:58<00:09, 101.59it/s, batch_loss=0.6465]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  87%|████████▋ | 6012/6926 [00:59<00:08, 101.99it/s, batch_loss=0.6477]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6000/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████▊ | 6111/6926 [01:00<00:07, 102.21it/s, batch_loss=0.6976]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|████████▉ | 6210/6926 [01:01<00:07, 102.23it/s, batch_loss=0.6761]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  91%|█████████▏| 6320/6926 [01:02<00:05, 101.36it/s, batch_loss=0.6610]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  93%|█████████▎| 6419/6926 [01:03<00:05, 101.12it/s, batch_loss=0.6720]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0005\n",
      "Style Loss: 0.6604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 6518/6926 [01:04<00:04, 101.01it/s, batch_loss=0.6890]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  96%|█████████▌| 6617/6926 [01:05<00:03, 100.94it/s, batch_loss=0.6895]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|█████████▋| 6716/6926 [01:06<00:02, 100.35it/s, batch_loss=0.6650]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████▊| 6813/6926 [01:07<00:01, 98.68it/s, batch_loss=0.6842] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████▉| 6912/6926 [01:08<00:00, 101.89it/s, batch_loss=0.7053]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 6926/6926 [01:08<00:00, 100.66it/s, batch_loss=0.6547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed epoch. Average loss: 0.6746\n",
      "Epoch 2/10, Loss: 0.6746\n",
      "\n",
      "Epoch 3/10\n",
      "--------------------------------------------------\n",
      "\n",
      "Training on 443259 examples with 6926 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 10/6926 [00:00<01:12, 95.09it/s, batch_loss=0.6636]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First batch shapes:\n",
      "Input tokens: torch.Size([64, 15])\n",
      "Style labels: torch.Size([64])\n",
      "Sequence lengths: [10, 12, 12, 12, 7] (showing first 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 120/6926 [00:01<01:07, 100.46it/s, batch_loss=0.6794]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 219/6926 [00:02<01:06, 100.90it/s, batch_loss=0.6832]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 318/6926 [00:03<01:04, 101.69it/s, batch_loss=0.7154]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 417/6926 [00:04<01:04, 101.13it/s, batch_loss=0.7012]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 31.5431\n",
      "Style Loss: 0.7070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 514/6926 [00:05<01:04, 99.97it/s, batch_loss=0.7155] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 611/6926 [00:06<01:02, 100.54it/s, batch_loss=0.7091]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0031\n",
      "Style Loss: 0.6749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 710/6926 [00:07<01:00, 102.19it/s, batch_loss=0.6287]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 820/6926 [00:08<01:00, 101.58it/s, batch_loss=0.6785]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 919/6926 [00:09<00:59, 101.07it/s, batch_loss=0.6368]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 1018/6926 [00:10<00:58, 101.56it/s, batch_loss=0.7367]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1000/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 1117/6926 [00:11<00:56, 102.49it/s, batch_loss=0.6818]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.7260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 1216/6926 [00:12<00:56, 101.58it/s, batch_loss=0.6597]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 1314/6926 [00:13<00:55, 101.10it/s, batch_loss=0.6981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 1413/6926 [00:14<00:54, 100.86it/s, batch_loss=0.6480]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 1512/6926 [00:15<00:54, 98.96it/s, batch_loss=0.7217] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 1611/6926 [00:16<00:52, 100.90it/s, batch_loss=0.6645]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 1717/6926 [00:17<00:52, 99.74it/s, batch_loss=0.6773] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 1815/6926 [00:18<00:51, 99.40it/s, batch_loss=0.7237] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 1919/6926 [00:19<00:50, 98.40it/s, batch_loss=0.6413]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|██▉       | 2012/6926 [00:20<00:49, 98.97it/s, batch_loss=0.6481]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 2111/6926 [00:21<00:47, 101.42it/s, batch_loss=0.6615]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|███▏      | 2210/6926 [00:22<00:46, 101.36it/s, batch_loss=0.7139]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|███▎      | 2309/6926 [00:23<00:46, 100.08it/s, batch_loss=0.6545]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▍      | 2417/6926 [00:24<00:44, 100.95it/s, batch_loss=0.7108]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|███▋      | 2516/6926 [00:25<00:43, 100.91it/s, batch_loss=0.6288]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 2615/6926 [00:26<00:42, 101.67it/s, batch_loss=0.6256]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███▉      | 2712/6926 [00:27<00:42, 99.88it/s, batch_loss=0.6866] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|████      | 2811/6926 [00:28<00:40, 101.44it/s, batch_loss=0.6734]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|████▏     | 2910/6926 [00:28<00:39, 102.06it/s, batch_loss=0.6911]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|████▎     | 3020/6926 [00:29<00:38, 101.67it/s, batch_loss=0.6534]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3000/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▌     | 3119/6926 [00:30<00:37, 102.41it/s, batch_loss=0.6527]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|████▋     | 3218/6926 [00:31<00:36, 102.10it/s, batch_loss=0.6625]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|████▊     | 3317/6926 [00:32<00:36, 98.50it/s, batch_loss=0.7127] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|████▉     | 3416/6926 [00:33<00:34, 101.18it/s, batch_loss=0.7285]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  51%|█████     | 3515/6926 [00:34<00:34, 99.76it/s, batch_loss=0.6883] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|█████▏    | 3610/6926 [00:35<00:32, 100.55it/s, batch_loss=0.6780]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|█████▎    | 3718/6926 [00:36<00:32, 100.11it/s, batch_loss=0.6569]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0026\n",
      "Style Loss: 0.6708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 3814/6926 [00:37<00:31, 98.54it/s, batch_loss=0.6104] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▋    | 3910/6926 [00:38<00:30, 98.61it/s, batch_loss=0.7190] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|█████▊    | 4016/6926 [00:39<00:29, 98.93it/s, batch_loss=0.6444] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|█████▉    | 4119/6926 [00:40<00:28, 97.23it/s, batch_loss=0.6993]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|██████    | 4217/6926 [00:41<00:26, 100.89it/s, batch_loss=0.6698]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|██████▏   | 4313/6926 [00:42<00:26, 100.31it/s, batch_loss=0.6762]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|██████▍   | 4420/6926 [00:43<00:25, 99.71it/s, batch_loss=0.6812] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 4517/6926 [00:44<00:24, 99.99it/s, batch_loss=0.6376] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|██████▋   | 4618/6926 [00:45<00:23, 98.35it/s, batch_loss=0.6464]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|██████▊   | 4711/6926 [00:47<00:22, 99.59it/s, batch_loss=0.6866]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|██████▉   | 4818/6926 [00:48<00:21, 100.06it/s, batch_loss=0.6323]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 4915/6926 [00:49<00:20, 98.52it/s, batch_loss=0.6337] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|███████▏  | 5018/6926 [00:50<00:19, 99.36it/s, batch_loss=0.6973]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████▍  | 5119/6926 [00:51<00:18, 99.15it/s, batch_loss=0.6683]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 5215/6926 [00:52<00:17, 98.45it/s, batch_loss=0.6951] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 1.0453\n",
      "Style Loss: 0.6138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|███████▋  | 5318/6926 [00:53<00:16, 100.01it/s, batch_loss=0.6393]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|███████▊  | 5419/6926 [00:54<00:15, 99.93it/s, batch_loss=0.6402] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|███████▉  | 5510/6926 [00:55<00:14, 98.54it/s, batch_loss=0.6958]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  81%|████████  | 5610/6926 [00:56<00:13, 98.01it/s, batch_loss=0.6950]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|████████▎ | 5715/6926 [00:57<00:12, 99.91it/s, batch_loss=0.6841] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  84%|████████▍ | 5819/6926 [00:58<00:11, 99.76it/s, batch_loss=0.6492] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 5913/6926 [00:59<00:10, 99.03it/s, batch_loss=0.6690]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  87%|████████▋ | 6015/6926 [01:00<00:09, 98.26it/s, batch_loss=0.6832]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████▊ | 6115/6926 [01:01<00:08, 98.29it/s, batch_loss=0.6867]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6100/6926\n",
      "Reconstruction Loss: 0.0002\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|████████▉ | 6216/6926 [01:02<00:07, 98.73it/s, batch_loss=0.6474]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.7100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  91%|█████████ | 6318/6926 [01:03<00:06, 99.19it/s, batch_loss=0.6658]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  93%|█████████▎| 6410/6926 [01:04<00:05, 98.99it/s, batch_loss=0.6806]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 6512/6926 [01:05<00:04, 98.61it/s, batch_loss=0.6534]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  96%|█████████▌| 6618/6926 [01:06<00:03, 99.92it/s, batch_loss=0.7003] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6600/6926\n",
      "Reconstruction Loss: 0.0001\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|█████████▋| 6715/6926 [01:07<00:02, 100.07it/s, batch_loss=0.7272]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: -0.0000\n",
      "Style Loss: 0.6302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████▊| 6814/6926 [01:08<00:01, 100.13it/s, batch_loss=0.7067]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████▉| 6913/6926 [01:09<00:00, 99.87it/s, batch_loss=0.6438] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 6926/6926 [01:09<00:00, 99.94it/s, batch_loss=0.6758]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed epoch. Average loss: 0.6789\n",
      "Epoch 3/10, Loss: 0.6789\n",
      "\n",
      "Epoch 4/10\n",
      "--------------------------------------------------\n",
      "\n",
      "Training on 443259 examples with 6926 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 10/6926 [00:00<01:15, 91.76it/s, batch_loss=0.6716]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First batch shapes:\n",
      "Input tokens: torch.Size([64, 15])\n",
      "Style labels: torch.Size([64])\n",
      "Sequence lengths: [14, 6, 4, 7, 11] (showing first 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 116/6926 [00:01<01:08, 100.14it/s, batch_loss=0.7260]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 212/6926 [00:02<01:07, 99.55it/s, batch_loss=0.7067] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 316/6926 [00:03<01:06, 99.66it/s, batch_loss=0.6659]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 417/6926 [00:04<01:05, 99.25it/s, batch_loss=0.6690]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 519/6926 [00:05<01:05, 98.03it/s, batch_loss=0.6599]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 610/6926 [00:06<01:03, 99.46it/s, batch_loss=0.6640]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 711/6926 [00:07<01:03, 98.51it/s, batch_loss=0.6973]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 812/6926 [00:08<01:02, 98.54it/s, batch_loss=0.6631]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 912/6926 [00:09<01:02, 96.98it/s, batch_loss=0.6312]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 1013/6926 [00:10<01:00, 97.77it/s, batch_loss=0.6841]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 1113/6926 [00:11<00:59, 97.81it/s, batch_loss=0.6779]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 1216/6926 [00:12<00:57, 98.72it/s, batch_loss=0.6730]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 1317/6926 [00:13<00:58, 96.69it/s, batch_loss=0.7199]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 1410/6926 [00:14<00:55, 99.54it/s, batch_loss=0.7030]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 1517/6926 [00:15<00:55, 97.94it/s, batch_loss=0.6589] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 1610/6926 [00:16<00:53, 99.29it/s, batch_loss=0.6455]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 1715/6926 [00:17<00:52, 99.94it/s, batch_loss=0.6608]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▋       | 1819/6926 [00:18<00:51, 99.89it/s, batch_loss=0.6932] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 1912/6926 [00:19<00:50, 99.50it/s, batch_loss=0.6518] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|██▉       | 2016/6926 [00:20<00:49, 99.64it/s, batch_loss=0.6902]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 2111/6926 [00:21<00:48, 98.66it/s, batch_loss=0.6487] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|███▏      | 2209/6926 [00:22<00:47, 100.26it/s, batch_loss=0.6491]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|███▎      | 2315/6926 [00:23<00:46, 99.97it/s, batch_loss=0.6884] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▍      | 2409/6926 [00:24<00:46, 97.20it/s, batch_loss=0.6555] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|███▌      | 2510/6926 [00:25<00:44, 99.83it/s, batch_loss=0.6421]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 2611/6926 [00:26<00:43, 98.64it/s, batch_loss=0.6600]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███▉      | 2715/6926 [00:27<00:42, 99.37it/s, batch_loss=0.6659]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|████      | 2816/6926 [00:28<00:42, 97.40it/s, batch_loss=0.6479]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|████▏     | 2916/6926 [00:29<00:41, 96.65it/s, batch_loss=0.6559]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|████▎     | 3016/6926 [00:30<00:39, 98.66it/s, batch_loss=0.6849]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▌     | 3117/6926 [00:31<00:38, 98.37it/s, batch_loss=0.6646]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.7019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|████▋     | 3217/6926 [00:32<00:37, 98.18it/s, batch_loss=0.6841]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|████▊     | 3317/6926 [00:33<00:38, 94.15it/s, batch_loss=0.6857]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|████▉     | 3419/6926 [00:34<00:35, 97.93it/s, batch_loss=0.7019]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  51%|█████     | 3513/6926 [00:35<00:34, 99.78it/s, batch_loss=0.6779]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|█████▏    | 3618/6926 [00:36<00:33, 99.48it/s, batch_loss=0.7033] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|█████▎    | 3717/6926 [00:37<00:31, 101.31it/s, batch_loss=0.6379]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 3816/6926 [00:38<00:30, 101.00it/s, batch_loss=0.7090]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 3915/6926 [00:39<00:30, 100.17it/s, batch_loss=0.6365]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|█████▊    | 4013/6926 [00:40<00:29, 100.03it/s, batch_loss=0.6445]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|█████▉    | 4111/6926 [00:41<00:28, 100.46it/s, batch_loss=0.6836]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|██████    | 4210/6926 [00:42<00:27, 100.57it/s, batch_loss=0.6768]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|██████▏   | 4320/6926 [00:43<00:25, 100.75it/s, batch_loss=0.6767]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|██████▍   | 4419/6926 [00:44<00:24, 101.73it/s, batch_loss=0.6984]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 4518/6926 [00:45<00:24, 99.10it/s, batch_loss=0.6545] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|██████▋   | 4616/6926 [00:46<00:22, 101.79it/s, batch_loss=0.6540]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|██████▊   | 4715/6926 [00:47<00:21, 101.54it/s, batch_loss=0.6685]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|██████▉   | 4814/6926 [00:48<00:21, 99.85it/s, batch_loss=0.6701] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 4913/6926 [00:49<00:19, 101.11it/s, batch_loss=0.6638]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|███████▏  | 5012/6926 [00:50<00:18, 100.93it/s, batch_loss=0.6841]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████▍  | 5111/6926 [00:51<00:18, 100.58it/s, batch_loss=0.6266]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 5210/6926 [00:52<00:17, 100.00it/s, batch_loss=0.6297]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|███████▋  | 5319/6926 [00:53<00:15, 100.62it/s, batch_loss=0.6700]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|███████▊  | 5414/6926 [00:54<00:15, 99.70it/s, batch_loss=0.6822] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|███████▉  | 5512/6926 [00:55<00:14, 100.63it/s, batch_loss=0.7010]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  81%|████████  | 5611/6926 [00:56<00:13, 99.43it/s, batch_loss=0.6898] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|████████▎ | 5714/6926 [00:57<00:12, 100.05it/s, batch_loss=0.6617]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  84%|████████▍ | 5813/6926 [00:58<00:10, 101.53it/s, batch_loss=0.6401]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 5912/6926 [00:59<00:09, 101.71it/s, batch_loss=0.6848]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.7080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  87%|████████▋ | 6011/6926 [01:00<00:09, 100.84it/s, batch_loss=0.6778]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████▊ | 6116/6926 [01:01<00:08, 99.81it/s, batch_loss=0.6319] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|████████▉ | 6213/6926 [01:02<00:07, 99.88it/s, batch_loss=0.7098] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  91%|█████████ | 6318/6926 [01:03<00:06, 100.58it/s, batch_loss=0.6718]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  93%|█████████▎| 6417/6926 [01:04<00:05, 99.98it/s, batch_loss=0.7024] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 6512/6926 [01:05<00:04, 100.37it/s, batch_loss=0.7316]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.7332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|█████████▌| 6610/6926 [01:06<00:03, 100.74it/s, batch_loss=0.6823]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|█████████▋| 6716/6926 [01:07<00:02, 99.41it/s, batch_loss=0.6370] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████▊| 6814/6926 [01:08<00:01, 100.05it/s, batch_loss=0.7112]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████▉| 6911/6926 [01:09<00:00, 100.29it/s, batch_loss=0.6858]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 6926/6926 [01:09<00:00, 99.43it/s, batch_loss=0.6708] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed epoch. Average loss: 0.6739\n",
      "Epoch 4/10, Loss: 0.6739\n",
      "\n",
      "Epoch 5/10\n",
      "--------------------------------------------------\n",
      "\n",
      "Training on 443259 examples with 6926 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 10/6926 [00:00<01:14, 92.40it/s, batch_loss=0.6606]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First batch shapes:\n",
      "Input tokens: torch.Size([64, 15])\n",
      "Style labels: torch.Size([64])\n",
      "Sequence lengths: [3, 8, 6, 6, 10] (showing first 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 120/6926 [00:01<01:07, 101.33it/s, batch_loss=0.6431]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 219/6926 [00:02<01:06, 100.80it/s, batch_loss=0.6525]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.7024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 318/6926 [00:03<01:05, 100.56it/s, batch_loss=0.6519]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 417/6926 [00:04<01:04, 100.56it/s, batch_loss=0.6822]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0000\n",
      "Style Loss: 0.6622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 516/6926 [00:05<01:03, 101.62it/s, batch_loss=0.6779]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 615/6926 [00:06<01:02, 101.44it/s, batch_loss=0.6516]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 714/6926 [00:07<01:00, 102.24it/s, batch_loss=0.7108]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 813/6926 [00:08<01:00, 101.49it/s, batch_loss=0.6790]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 912/6926 [00:09<00:59, 101.09it/s, batch_loss=0.6442]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 1011/6926 [00:10<00:58, 101.11it/s, batch_loss=0.6404]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 1110/6926 [00:11<00:57, 100.32it/s, batch_loss=0.6368]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 1220/6926 [00:12<00:56, 101.14it/s, batch_loss=0.6667]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 1318/6926 [00:13<00:55, 100.88it/s, batch_loss=0.6737]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 1417/6926 [00:14<00:54, 101.83it/s, batch_loss=0.7108]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 1516/6926 [00:15<00:52, 102.11it/s, batch_loss=0.6917]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 1615/6926 [00:16<00:51, 102.46it/s, batch_loss=0.7169]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 1714/6926 [00:16<00:51, 102.10it/s, batch_loss=0.7036]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 1813/6926 [00:17<00:50, 100.91it/s, batch_loss=0.6567]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 1912/6926 [00:18<00:49, 101.57it/s, batch_loss=0.6674]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|██▉       | 2011/6926 [00:19<00:49, 99.86it/s, batch_loss=0.6784] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 2110/6926 [00:20<00:47, 100.91it/s, batch_loss=0.6553]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|███▏      | 2220/6926 [00:21<00:46, 101.03it/s, batch_loss=0.6421]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|███▎      | 2318/6926 [00:22<00:46, 99.44it/s, batch_loss=0.6977] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▍      | 2413/6926 [00:23<00:44, 100.79it/s, batch_loss=0.6761]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|███▋      | 2512/6926 [00:24<00:43, 100.91it/s, batch_loss=0.6680]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 2611/6926 [00:25<00:42, 101.20it/s, batch_loss=0.6706]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███▉      | 2710/6926 [00:26<00:41, 101.51it/s, batch_loss=0.6285]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|████      | 2820/6926 [00:27<00:40, 101.14it/s, batch_loss=0.6898]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|████▏     | 2919/6926 [00:28<00:39, 101.77it/s, batch_loss=0.6163]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|████▎     | 3018/6926 [00:29<00:38, 100.36it/s, batch_loss=0.6984]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▌     | 3117/6926 [00:30<00:37, 100.68it/s, batch_loss=0.6358]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|████▋     | 3216/6926 [00:31<00:37, 100.06it/s, batch_loss=0.6819]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|████▊     | 3313/6926 [00:32<00:36, 99.54it/s, batch_loss=0.6591] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|████▉     | 3419/6926 [00:33<00:34, 100.63it/s, batch_loss=0.6360]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  51%|█████     | 3518/6926 [00:34<00:33, 101.55it/s, batch_loss=0.6388]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|█████▏    | 3617/6926 [00:35<00:32, 101.76it/s, batch_loss=0.6112]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|█████▎    | 3716/6926 [00:36<00:31, 102.39it/s, batch_loss=0.6542]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 3815/6926 [00:37<00:30, 101.21it/s, batch_loss=0.6605]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.7008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▋    | 3913/6926 [00:38<00:30, 98.31it/s, batch_loss=0.7069] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.7414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|█████▊    | 4009/6926 [00:39<00:29, 99.61it/s, batch_loss=0.6758] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|█████▉    | 4112/6926 [00:40<00:28, 98.48it/s, batch_loss=0.7110]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|██████    | 4215/6926 [00:41<00:27, 99.27it/s, batch_loss=0.7429]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|██████▏   | 4311/6926 [00:42<00:25, 101.28it/s, batch_loss=0.6896]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|██████▎   | 4410/6926 [00:43<00:24, 101.21it/s, batch_loss=0.6833]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 4520/6926 [00:44<00:23, 100.79it/s, batch_loss=0.6962]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|██████▋   | 4619/6926 [00:45<00:22, 101.41it/s, batch_loss=0.6971]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|██████▊   | 4718/6926 [00:46<00:22, 99.78it/s, batch_loss=0.7258] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|██████▉   | 4814/6926 [00:47<00:21, 99.84it/s, batch_loss=0.6414] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 4911/6926 [00:48<00:20, 99.99it/s, batch_loss=0.6763] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|███████▏  | 5015/6926 [00:49<00:19, 99.85it/s, batch_loss=0.7038] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████▍  | 5117/6926 [00:50<00:18, 99.97it/s, batch_loss=0.6843]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 5213/6926 [00:51<00:17, 100.00it/s, batch_loss=0.6578]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|███████▋  | 5310/6926 [00:52<00:16, 100.41it/s, batch_loss=0.7003]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|███████▊  | 5417/6926 [00:53<00:15, 99.94it/s, batch_loss=0.6041] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|███████▉  | 5515/6926 [00:54<00:13, 100.99it/s, batch_loss=0.6492]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  81%|████████  | 5614/6926 [00:55<00:12, 101.72it/s, batch_loss=0.6421]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%|████████▏ | 5713/6926 [00:56<00:11, 101.50it/s, batch_loss=0.6768]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  84%|████████▍ | 5812/6926 [00:57<00:10, 101.81it/s, batch_loss=0.6930]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 5911/6926 [00:58<00:09, 101.94it/s, batch_loss=0.6955]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  87%|████████▋ | 6020/6926 [00:59<00:09, 100.47it/s, batch_loss=0.6628]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████▊ | 6119/6926 [01:00<00:08, 100.22it/s, batch_loss=0.6580]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|████████▉ | 6217/6926 [01:01<00:07, 100.52it/s, batch_loss=0.6916]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  91%|█████████ | 6316/6926 [01:02<00:06, 99.51it/s, batch_loss=0.6955] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  93%|█████████▎| 6413/6926 [01:03<00:05, 101.13it/s, batch_loss=0.6566]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 6512/6926 [01:04<00:04, 100.58it/s, batch_loss=0.6482]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|█████████▌| 6611/6926 [01:05<00:03, 101.01it/s, batch_loss=0.6786]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|█████████▋| 6710/6926 [01:06<00:02, 100.72it/s, batch_loss=0.6783]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████▊| 6820/6926 [01:07<00:01, 101.54it/s, batch_loss=0.6607]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████▉| 6917/6926 [01:08<00:00, 100.94it/s, batch_loss=0.7039]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 6926/6926 [01:08<00:00, 100.65it/s, batch_loss=0.7080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed epoch. Average loss: 0.6737\n",
      "Epoch 5/10, Loss: 0.6737\n",
      "\n",
      "Epoch 6/10\n",
      "--------------------------------------------------\n",
      "\n",
      "Training on 443259 examples with 6926 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 10/6926 [00:00<01:12, 95.57it/s, batch_loss=0.7163]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First batch shapes:\n",
      "Input tokens: torch.Size([64, 15])\n",
      "Style labels: torch.Size([64])\n",
      "Sequence lengths: [4, 10, 15, 14, 4] (showing first 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 120/6926 [00:01<01:06, 101.63it/s, batch_loss=0.7107]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 219/6926 [00:02<01:06, 101.27it/s, batch_loss=0.6602]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 318/6926 [00:03<01:05, 101.02it/s, batch_loss=0.6919]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 417/6926 [00:04<01:04, 100.91it/s, batch_loss=0.7051]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 516/6926 [00:05<01:03, 101.20it/s, batch_loss=0.6502]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 615/6926 [00:06<01:01, 102.44it/s, batch_loss=0.6440]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 714/6926 [00:07<01:01, 101.38it/s, batch_loss=0.6638]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 813/6926 [00:08<01:00, 101.63it/s, batch_loss=0.6650]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 911/6926 [00:09<01:00, 100.25it/s, batch_loss=0.6864]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 1018/6926 [00:10<00:58, 100.81it/s, batch_loss=0.6751]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 1117/6926 [00:11<00:59, 98.43it/s, batch_loss=0.6720] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 1211/6926 [00:12<00:57, 99.86it/s, batch_loss=0.6599]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 1319/6926 [00:13<00:55, 100.58it/s, batch_loss=0.6437]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 1418/6926 [00:14<00:55, 99.46it/s, batch_loss=0.6619] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 1517/6926 [00:15<00:53, 100.17it/s, batch_loss=0.6988]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 1616/6926 [00:16<00:52, 100.90it/s, batch_loss=0.6376]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 1715/6926 [00:17<00:51, 100.33it/s, batch_loss=0.6913]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 1814/6926 [00:18<00:50, 101.00it/s, batch_loss=0.6941]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 1913/6926 [00:19<00:49, 100.92it/s, batch_loss=0.7147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|██▉       | 2012/6926 [00:20<00:48, 101.66it/s, batch_loss=0.6623]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 2111/6926 [00:21<00:47, 101.19it/s, batch_loss=0.7208]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|███▏      | 2210/6926 [00:22<00:46, 101.56it/s, batch_loss=0.6925]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|███▎      | 2309/6926 [00:23<00:46, 100.20it/s, batch_loss=0.6629]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▍      | 2415/6926 [00:24<00:45, 99.07it/s, batch_loss=0.6793] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|███▋      | 2519/6926 [00:25<00:44, 99.60it/s, batch_loss=0.6803]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.7221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 2611/6926 [00:26<00:43, 98.96it/s, batch_loss=0.6690]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███▉      | 2717/6926 [00:27<00:42, 99.92it/s, batch_loss=0.6823] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|████      | 2816/6926 [00:28<00:40, 101.52it/s, batch_loss=0.6775]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|████▏     | 2915/6926 [00:29<00:39, 101.39it/s, batch_loss=0.6778]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|████▎     | 3014/6926 [00:30<00:38, 102.19it/s, batch_loss=0.6456]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▍     | 3113/6926 [00:30<00:37, 101.58it/s, batch_loss=0.6821]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|████▋     | 3212/6926 [00:31<00:36, 101.64it/s, batch_loss=0.7016]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|████▊     | 3311/6926 [00:32<00:35, 101.73it/s, batch_loss=0.6735]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|████▉     | 3410/6926 [00:33<00:34, 100.62it/s, batch_loss=0.6888]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  51%|█████     | 3519/6926 [00:34<00:33, 100.37it/s, batch_loss=0.7134]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|█████▏    | 3618/6926 [00:35<00:33, 99.93it/s, batch_loss=0.6349] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|█████▎    | 3717/6926 [00:36<00:31, 100.73it/s, batch_loss=0.6844]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 3815/6926 [00:37<00:31, 100.35it/s, batch_loss=0.6338]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 3914/6926 [00:38<00:30, 100.40it/s, batch_loss=0.6304]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|█████▊    | 4013/6926 [00:39<00:29, 100.27it/s, batch_loss=0.6831]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|█████▉    | 4111/6926 [00:40<00:27, 100.99it/s, batch_loss=0.7025]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|██████    | 4210/6926 [00:41<00:27, 99.04it/s, batch_loss=0.6902] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|██████▏   | 4320/6926 [00:42<00:25, 101.54it/s, batch_loss=0.6603]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|██████▍   | 4418/6926 [00:43<00:25, 98.48it/s, batch_loss=0.6399] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 4515/6926 [00:44<00:23, 100.47it/s, batch_loss=0.6755]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|██████▋   | 4613/6926 [00:45<00:23, 100.07it/s, batch_loss=0.6817]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|██████▊   | 4712/6926 [00:46<00:21, 101.30it/s, batch_loss=0.6699]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|██████▉   | 4811/6926 [00:47<00:20, 102.12it/s, batch_loss=0.6463]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 4910/6926 [00:48<00:19, 101.38it/s, batch_loss=0.6177]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|███████▏  | 5019/6926 [00:49<00:18, 101.52it/s, batch_loss=0.6694]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████▍  | 5118/6926 [00:50<00:17, 102.10it/s, batch_loss=0.6480]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 5217/6926 [00:51<00:16, 102.39it/s, batch_loss=0.6619]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|███████▋  | 5316/6926 [00:52<00:15, 101.70it/s, batch_loss=0.6731]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|███████▊  | 5415/6926 [00:53<00:15, 100.71it/s, batch_loss=0.6453]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|███████▉  | 5514/6926 [00:54<00:14, 100.01it/s, batch_loss=0.6443]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  81%|████████  | 5610/6926 [00:55<00:13, 99.78it/s, batch_loss=0.6934] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|████████▎ | 5715/6926 [00:56<00:12, 100.70it/s, batch_loss=0.6765]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  84%|████████▍ | 5814/6926 [00:57<00:11, 100.72it/s, batch_loss=0.6620]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 5913/6926 [00:58<00:10, 101.06it/s, batch_loss=0.7006]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  87%|████████▋ | 6012/6926 [00:59<00:09, 100.88it/s, batch_loss=0.6534]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████▊ | 6111/6926 [01:00<00:08, 101.25it/s, batch_loss=0.6807]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|████████▉ | 6210/6926 [01:01<00:07, 101.62it/s, batch_loss=0.6677]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  91%|█████████▏| 6320/6926 [01:02<00:05, 101.10it/s, batch_loss=0.6594]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  93%|█████████▎| 6419/6926 [01:03<00:05, 100.73it/s, batch_loss=0.6875]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 6518/6926 [01:04<00:04, 100.86it/s, batch_loss=0.7087]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  96%|█████████▌| 6617/6926 [01:05<00:03, 100.72it/s, batch_loss=0.6634]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|█████████▋| 6715/6926 [01:06<00:02, 100.75it/s, batch_loss=0.6966]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████▊| 6812/6926 [01:07<00:01, 99.75it/s, batch_loss=0.6974] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████▉| 6918/6926 [01:08<00:00, 101.45it/s, batch_loss=0.6895]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 6926/6926 [01:08<00:00, 100.67it/s, batch_loss=0.6931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed epoch. Average loss: 0.6735\n",
      "Epoch 6/10, Loss: 0.6735\n",
      "\n",
      "Epoch 7/10\n",
      "--------------------------------------------------\n",
      "\n",
      "Training on 443259 examples with 6926 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 10/6926 [00:00<01:15, 91.63it/s, batch_loss=0.6762]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First batch shapes:\n",
      "Input tokens: torch.Size([64, 15])\n",
      "Style labels: torch.Size([64])\n",
      "Sequence lengths: [14, 3, 13, 15, 6] (showing first 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 119/6926 [00:01<01:07, 100.69it/s, batch_loss=0.6572]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 218/6926 [00:02<01:05, 101.82it/s, batch_loss=0.6394]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 317/6926 [00:03<01:05, 101.28it/s, batch_loss=0.7132]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 416/6926 [00:04<01:05, 98.99it/s, batch_loss=0.6155] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 514/6926 [00:05<01:03, 101.46it/s, batch_loss=0.7179]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 613/6926 [00:06<01:02, 101.63it/s, batch_loss=0.6469]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 711/6926 [00:07<01:03, 98.63it/s, batch_loss=0.6916] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 819/6926 [00:08<01:00, 100.59it/s, batch_loss=0.6417]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 918/6926 [00:09<00:59, 101.25it/s, batch_loss=0.6195]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 1017/6926 [00:10<00:58, 100.95it/s, batch_loss=0.6906]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 1116/6926 [00:11<00:57, 100.87it/s, batch_loss=0.7013]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 1215/6926 [00:12<00:56, 100.83it/s, batch_loss=0.6570]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 1312/6926 [00:13<00:55, 100.34it/s, batch_loss=0.6621]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 1411/6926 [00:14<00:54, 101.45it/s, batch_loss=0.6456]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 1510/6926 [00:15<00:53, 101.70it/s, batch_loss=0.6671]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 1620/6926 [00:16<00:52, 100.30it/s, batch_loss=0.6445]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 1719/6926 [00:17<00:51, 100.74it/s, batch_loss=0.7108]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 1818/6926 [00:18<00:50, 101.46it/s, batch_loss=0.6511]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 1917/6926 [00:19<00:49, 101.62it/s, batch_loss=0.7136]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|██▉       | 2016/6926 [00:20<00:48, 101.00it/s, batch_loss=0.7096]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  31%|███       | 2115/6926 [00:21<00:47, 100.70it/s, batch_loss=0.7075]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|███▏      | 2214/6926 [00:22<00:46, 101.70it/s, batch_loss=0.6687]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|███▎      | 2313/6926 [00:23<00:45, 102.30it/s, batch_loss=0.6944]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▍      | 2412/6926 [00:23<00:44, 102.58it/s, batch_loss=0.6986]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|███▋      | 2511/6926 [00:24<00:43, 102.01it/s, batch_loss=0.6976]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 2610/6926 [00:25<00:42, 101.47it/s, batch_loss=0.6706]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███▉      | 2720/6926 [00:26<00:41, 101.55it/s, batch_loss=0.7075]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|████      | 2819/6926 [00:27<00:40, 101.24it/s, batch_loss=0.7048]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|████▏     | 2918/6926 [00:28<00:39, 100.87it/s, batch_loss=0.6526]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|████▎     | 3017/6926 [00:29<00:38, 100.82it/s, batch_loss=0.6733]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▍     | 3116/6926 [00:30<00:37, 101.36it/s, batch_loss=0.6540]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|████▋     | 3215/6926 [00:31<00:36, 100.91it/s, batch_loss=0.6673]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|████▊     | 3314/6926 [00:32<00:35, 100.97it/s, batch_loss=0.6728]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|████▉     | 3412/6926 [00:33<00:34, 101.28it/s, batch_loss=0.6639]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  51%|█████     | 3511/6926 [00:34<00:33, 101.26it/s, batch_loss=0.6554]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|█████▏    | 3610/6926 [00:35<00:32, 102.10it/s, batch_loss=0.6947]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|█████▎    | 3720/6926 [00:36<00:31, 101.90it/s, batch_loss=0.6431]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 3819/6926 [00:37<00:30, 101.98it/s, batch_loss=0.6856]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 3918/6926 [00:38<00:29, 101.17it/s, batch_loss=0.6738]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|█████▊    | 4016/6926 [00:39<00:29, 100.33it/s, batch_loss=0.6386]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|█████▉    | 4115/6926 [00:40<00:27, 101.16it/s, batch_loss=0.6454]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|██████    | 4214/6926 [00:41<00:26, 101.50it/s, batch_loss=0.7295]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|██████▏   | 4312/6926 [00:42<00:25, 101.12it/s, batch_loss=0.6767]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|██████▎   | 4411/6926 [00:43<00:24, 102.04it/s, batch_loss=0.7085]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 4510/6926 [00:44<00:23, 102.35it/s, batch_loss=0.7032]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|██████▋   | 4620/6926 [00:45<00:22, 101.69it/s, batch_loss=0.7310]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|██████▊   | 4719/6926 [00:46<00:21, 101.48it/s, batch_loss=0.6924]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|██████▉   | 4817/6926 [00:47<00:21, 100.22it/s, batch_loss=0.6868]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 4915/6926 [00:48<00:20, 99.49it/s, batch_loss=0.6535] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|███████▏  | 5018/6926 [00:49<00:19, 99.31it/s, batch_loss=0.6703]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████▍  | 5115/6926 [00:50<00:18, 97.14it/s, batch_loss=0.7077] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 5220/6926 [00:51<00:17, 98.85it/s, batch_loss=0.6505]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|███████▋  | 5313/6926 [00:52<00:16, 99.38it/s, batch_loss=0.6667]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|███████▊  | 5415/6926 [00:53<00:15, 96.76it/s, batch_loss=0.6718]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|███████▉  | 5510/6926 [00:54<00:14, 99.86it/s, batch_loss=0.6637]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  81%|████████  | 5620/6926 [00:55<00:12, 100.87it/s, batch_loss=0.6614]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|████████▎ | 5717/6926 [00:56<00:12, 100.31it/s, batch_loss=0.6880]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  84%|████████▍ | 5816/6926 [00:57<00:11, 100.33it/s, batch_loss=0.6663]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 5915/6926 [00:58<00:10, 100.12it/s, batch_loss=0.6870]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  87%|████████▋ | 6011/6926 [00:59<00:09, 100.05it/s, batch_loss=0.6474]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████▊ | 6115/6926 [01:00<00:08, 99.93it/s, batch_loss=0.6478] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|████████▉ | 6210/6926 [01:01<00:07, 99.62it/s, batch_loss=0.6652] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  91%|█████████ | 6317/6926 [01:02<00:06, 101.04it/s, batch_loss=0.6892]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  93%|█████████▎| 6415/6926 [01:03<00:05, 101.37it/s, batch_loss=0.6824]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 6514/6926 [01:04<00:04, 100.64it/s, batch_loss=0.7163]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|█████████▌| 6613/6926 [01:05<00:03, 101.83it/s, batch_loss=0.6412]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|█████████▋| 6712/6926 [01:06<00:02, 102.05it/s, batch_loss=0.6618]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████▊| 6811/6926 [01:07<00:01, 100.46it/s, batch_loss=0.6259]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████▉| 6910/6926 [01:08<00:00, 99.17it/s, batch_loss=0.6592] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 6926/6926 [01:08<00:00, 100.63it/s, batch_loss=0.6977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed epoch. Average loss: 0.6735\n",
      "Epoch 7/10, Loss: 0.6735\n",
      "\n",
      "Epoch 8/10\n",
      "--------------------------------------------------\n",
      "\n",
      "Training on 443259 examples with 6926 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 10/6926 [00:00<01:14, 92.51it/s, batch_loss=0.7140]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First batch shapes:\n",
      "Input tokens: torch.Size([64, 15])\n",
      "Style labels: torch.Size([64])\n",
      "Sequence lengths: [7, 2, 12, 9, 6] (showing first 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 116/6926 [00:01<01:07, 100.62it/s, batch_loss=0.6767]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 215/6926 [00:02<01:06, 100.47it/s, batch_loss=0.6559]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 314/6926 [00:03<01:05, 101.23it/s, batch_loss=0.6722]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 413/6926 [00:04<01:04, 100.36it/s, batch_loss=0.6703]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 512/6926 [00:05<01:03, 101.24it/s, batch_loss=0.6973]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 611/6926 [00:06<01:03, 99.93it/s, batch_loss=0.6424] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 713/6926 [00:07<01:04, 96.92it/s, batch_loss=0.6665]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 812/6926 [00:08<01:00, 100.34it/s, batch_loss=0.7012]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 910/6926 [00:09<01:02, 96.12it/s, batch_loss=0.6851] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 1014/6926 [00:10<01:00, 98.37it/s, batch_loss=0.6003]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 1113/6926 [00:11<00:58, 99.67it/s, batch_loss=0.6603] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 1210/6926 [00:12<00:57, 98.92it/s, batch_loss=0.6432] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 1312/6926 [00:13<00:57, 97.61it/s, batch_loss=0.7086]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 1411/6926 [00:14<00:54, 100.46it/s, batch_loss=0.6996]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 1509/6926 [00:15<00:53, 100.40it/s, batch_loss=0.6864]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 1614/6926 [00:16<00:53, 98.80it/s, batch_loss=0.6733] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 1719/6926 [00:17<00:51, 101.01it/s, batch_loss=0.6847]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.7065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 1818/6926 [00:18<00:50, 100.48it/s, batch_loss=0.6633]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 1914/6926 [00:19<00:50, 99.32it/s, batch_loss=0.6230] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|██▉       | 2010/6926 [00:20<00:49, 100.13it/s, batch_loss=0.6591]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  31%|███       | 2115/6926 [00:21<00:48, 98.43it/s, batch_loss=0.6544] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|███▏      | 2217/6926 [00:22<00:47, 99.47it/s, batch_loss=0.6806]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|███▎      | 2320/6926 [00:23<00:46, 99.40it/s, batch_loss=0.6569]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▍      | 2411/6926 [00:24<00:45, 98.95it/s, batch_loss=0.6631]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|███▋      | 2512/6926 [00:25<00:45, 96.24it/s, batch_loss=0.6619]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 2614/6926 [00:26<00:43, 99.11it/s, batch_loss=0.7017]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███▉      | 2718/6926 [00:27<00:42, 99.77it/s, batch_loss=0.6686]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|████      | 2810/6926 [00:28<00:41, 98.53it/s, batch_loss=0.6680]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|████▏     | 2911/6926 [00:29<00:40, 99.19it/s, batch_loss=0.6556]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|████▎     | 3014/6926 [00:30<00:39, 99.86it/s, batch_loss=0.6846]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0002\n",
      "Style Loss: 0.6803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▌     | 3119/6926 [00:31<00:37, 100.38it/s, batch_loss=0.6867]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|████▋     | 3218/6926 [00:32<00:36, 100.50it/s, batch_loss=0.7093]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|████▊     | 3317/6926 [00:33<00:36, 98.89it/s, batch_loss=0.6291] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|████▉     | 3415/6926 [00:34<00:35, 100.26it/s, batch_loss=0.6754]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  51%|█████     | 3513/6926 [00:35<00:33, 101.44it/s, batch_loss=0.7068]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|█████▏    | 3612/6926 [00:36<00:33, 100.25it/s, batch_loss=0.7079]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|█████▎    | 3710/6926 [00:37<00:31, 100.89it/s, batch_loss=0.6913]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 3817/6926 [00:38<00:31, 99.86it/s, batch_loss=0.6889] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 3920/6926 [00:39<00:30, 99.61it/s, batch_loss=0.6232]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 3900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|█████▊    | 4018/6926 [00:40<00:29, 98.87it/s, batch_loss=0.6923] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|█████▉    | 4114/6926 [00:41<00:27, 101.17it/s, batch_loss=0.6089]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|██████    | 4213/6926 [00:42<00:26, 101.76it/s, batch_loss=0.7027]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|██████▏   | 4311/6926 [00:43<00:26, 99.60it/s, batch_loss=0.6182] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|██████▍   | 4419/6926 [00:44<00:25, 99.51it/s, batch_loss=0.6771] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 4509/6926 [00:45<00:24, 98.51it/s, batch_loss=0.6944]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|██████▋   | 4610/6926 [00:46<00:23, 96.54it/s, batch_loss=0.6595]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|██████▊   | 4714/6926 [00:47<00:22, 99.93it/s, batch_loss=0.6494]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|██████▉   | 4818/6926 [00:48<00:21, 98.14it/s, batch_loss=0.6744] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 4917/6926 [00:49<00:19, 101.85it/s, batch_loss=0.6922]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|███████▏  | 5016/6926 [00:50<00:18, 100.66it/s, batch_loss=0.6528]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████▍  | 5113/6926 [00:51<00:18, 98.22it/s, batch_loss=0.6545] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 5219/6926 [00:52<00:17, 100.38it/s, batch_loss=0.6505]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|███████▋  | 5317/6926 [00:53<00:16, 99.78it/s, batch_loss=0.6902] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|███████▊  | 5414/6926 [00:54<00:15, 100.72it/s, batch_loss=0.6757]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|███████▉  | 5513/6926 [00:55<00:14, 100.69it/s, batch_loss=0.6877]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  81%|████████  | 5612/6926 [00:56<00:13, 100.71it/s, batch_loss=0.6957]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|████████▎ | 5719/6926 [00:57<00:12, 99.95it/s, batch_loss=0.6322] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  84%|████████▍ | 5816/6926 [00:58<00:11, 100.62it/s, batch_loss=0.6648]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 5913/6926 [00:59<00:10, 99.10it/s, batch_loss=0.6264] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 5900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  87%|████████▋ | 6019/6926 [01:00<00:08, 101.30it/s, batch_loss=0.6380]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████▊ | 6118/6926 [01:01<00:08, 100.91it/s, batch_loss=0.6615]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|████████▉ | 6214/6926 [01:02<00:07, 100.14it/s, batch_loss=0.7136]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  91%|█████████ | 6311/6926 [01:03<00:06, 99.71it/s, batch_loss=0.6287] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  93%|█████████▎| 6409/6926 [01:04<00:05, 100.48it/s, batch_loss=0.6233]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 6512/6926 [01:05<00:04, 97.55it/s, batch_loss=0.6950] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  96%|█████████▌| 6618/6926 [01:06<00:03, 99.42it/s, batch_loss=0.6934] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|█████████▋| 6712/6926 [01:07<00:02, 99.63it/s, batch_loss=0.6766]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████▊| 6818/6926 [01:08<00:01, 99.57it/s, batch_loss=0.6873] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████▉| 6913/6926 [01:09<00:00, 99.91it/s, batch_loss=0.6878] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 6926/6926 [01:09<00:00, 99.57it/s, batch_loss=0.6506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed epoch. Average loss: 0.6734\n",
      "Epoch 8/10, Loss: 0.6734\n",
      "\n",
      "Epoch 9/10\n",
      "--------------------------------------------------\n",
      "\n",
      "Training on 443259 examples with 6926 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 9/6926 [00:00<01:16, 89.95it/s, batch_loss=0.6774]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First batch shapes:\n",
      "Input tokens: torch.Size([64, 15])\n",
      "Style labels: torch.Size([64])\n",
      "Sequence lengths: [9, 10, 14, 7, 10] (showing first 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 114/6926 [00:01<01:08, 99.92it/s, batch_loss=0.6625] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 221/6926 [00:02<01:04, 104.22it/s, batch_loss=0.6568]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.7035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 320/6926 [00:03<01:05, 101.02it/s, batch_loss=0.7227]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 418/6926 [00:04<01:05, 99.89it/s, batch_loss=0.6577] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 510/6926 [00:05<01:04, 99.90it/s, batch_loss=0.6403]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 617/6926 [00:06<01:03, 100.07it/s, batch_loss=0.6856]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 713/6926 [00:07<01:01, 100.35it/s, batch_loss=0.6720]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 812/6926 [00:08<01:00, 101.31it/s, batch_loss=0.6767]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 911/6926 [00:09<00:58, 102.19it/s, batch_loss=0.6897]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 900/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 1010/6926 [00:10<00:56, 104.41it/s, batch_loss=0.6957]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1000/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 1120/6926 [00:11<00:55, 104.97it/s, batch_loss=0.7050]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1100/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 1219/6926 [00:12<00:54, 103.97it/s, batch_loss=0.6588]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1200/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 1318/6926 [00:13<00:55, 100.37it/s, batch_loss=0.6866]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1300/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 1417/6926 [00:14<00:55, 100.13it/s, batch_loss=0.6830]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1400/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 1516/6926 [00:14<00:53, 101.22it/s, batch_loss=0.7111]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1500/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 1615/6926 [00:15<00:53, 100.14it/s, batch_loss=0.6662]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1600/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 1710/6926 [00:16<00:52, 99.43it/s, batch_loss=0.6228] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1700/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 1812/6926 [00:18<00:51, 99.81it/s, batch_loss=0.6641]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1800/6926\n",
      "Reconstruction Loss: 0.0000\n",
      "KL Loss: 0.0001\n",
      "Style Loss: 0.6789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 1878/6926 [00:18<00:49, 100.98it/s, batch_loss=0.6355]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 84\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m---> 84\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_vae_with_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvae\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[26], line 31\u001b[0m, in \u001b[0;36mtrain_vae_with_dataset\u001b[0;34m(vae, optimizer, data_loader, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m style_labels \u001b[38;5;241m=\u001b[39m style_labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m recon_x, style_mu, style_logvar, content_mu, content_logvar, style, content \u001b[38;5;241m=\u001b[39m \u001b[43mvae\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Calculate losses\u001b[39;00m\n\u001b[1;32m     34\u001b[0m loss_vae \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(recon_x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, recon_x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), input_tokens\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[24], line 113\u001b[0m, in \u001b[0;36mDisentangledVAE.forward\u001b[0;34m(self, x, lengths)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, lengths\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# Encode\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     style_mu, style_logvar, content_mu, content_logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Sample latent vectors\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     style \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreparameterize(style_mu, style_logvar)\n",
      "Cell \u001b[0;32mIn[24], line 68\u001b[0m, in \u001b[0;36mDisentangledVAE.encode\u001b[0;34m(self, x, lengths)\u001b[0m\n\u001b[1;32m     63\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mpack_padded_sequence(\n\u001b[1;32m     64\u001b[0m         embedded, lengths, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, enforce_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     )\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Encode\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m _, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_rnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Combine bidirectional states\u001b[39;00m\n\u001b[1;32m     70\u001b[0m hidden \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([hidden[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], hidden[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/rnn.py:1150\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(orig_input, PackedSequence):\n\u001b[1;32m   1149\u001b[0m     output_packed \u001b[38;5;241m=\u001b[39m PackedSequence(output, batch_sizes, sorted_indices, unsorted_indices)\n\u001b[0;32m-> 1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output_packed, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute_hidden\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munsorted_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batched:  \u001b[38;5;66;03m# type: ignore[possibly-undefined]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/rnn.py:288\u001b[0m, in \u001b[0;36mRNNBase.permute_hidden\u001b[0;34m(self, hx, permutation)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m permutation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hx\n\u001b[0;32m--> 288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_permutation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpermutation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/rnn.py:26\u001b[0m, in \u001b[0;36m_apply_permutation\u001b[0;34m(tensor, permutation, dim)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply_permutation\u001b[39m(tensor: Tensor, permutation: Tensor, dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpermutation\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_vae_with_dataset(vae, optimizer, data_loader, device):\n",
    "    \"\"\"\n",
    "    Train the VAE with a custom dataset.\n",
    "    \"\"\"\n",
    "    vae.train()\n",
    "    total_loss = 0\n",
    "    num_batches = len(data_loader)\n",
    "    \n",
    "    print(f\"\\nTraining on {len(data_loader.dataset)} examples with {num_batches} batches\")\n",
    "    \n",
    "    # Progress bar\n",
    "    progress = tqdm(data_loader, total=num_batches, desc=\"Training\")\n",
    "    \n",
    "    batch_count = 0\n",
    "    for input_tokens, style_labels, lengths in progress:\n",
    "        batch_count += 1\n",
    "        batch_size = input_tokens.size(0)\n",
    "        \n",
    "        # Log batch information\n",
    "        if batch_count == 1:\n",
    "            print(f\"\\nFirst batch shapes:\")\n",
    "            print(f\"Input tokens: {input_tokens.shape}\")\n",
    "            print(f\"Style labels: {style_labels.shape}\")\n",
    "            print(f\"Sequence lengths: {lengths[:5]} (showing first 5)\")\n",
    "        \n",
    "        # Move data to device\n",
    "        input_tokens = input_tokens.to(device)\n",
    "        style_labels = style_labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        recon_x, style_mu, style_logvar, content_mu, content_logvar, style, content = vae(input_tokens, lengths)\n",
    "        \n",
    "        # Calculate losses\n",
    "        loss_vae = F.cross_entropy(recon_x.view(-1, recon_x.size(-1)), input_tokens.view(-1), ignore_index=0)\n",
    "        kl_style = -0.5 * torch.sum(1 + style_logvar - style_mu.pow(2) - style_logvar.exp())\n",
    "        kl_content = -0.5 * torch.sum(1 + content_logvar - content_mu.pow(2) - content_logvar.exp())\n",
    "        \n",
    "        style_preds = vae.classify_style(style).squeeze()\n",
    "        style_labels = style_labels.float()\n",
    "        loss_multi_task = F.binary_cross_entropy(style_preds, style_labels)\n",
    "        \n",
    "        # Total loss with coefficient scaling\n",
    "        loss = loss_vae + 0.1 * (kl_style + kl_content) + loss_multi_task\n",
    "        \n",
    "        # Optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(vae.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update progress bar with current loss\n",
    "        progress.set_postfix({'batch_loss': f'{loss.item():.4f}'})\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Detailed loss logging every 100 batches\n",
    "        if batch_count % 100 == 0:\n",
    "            print(f\"\\nBatch {batch_count}/{num_batches}\")\n",
    "            print(f\"Reconstruction Loss: {loss_vae.item():.4f}\")\n",
    "            print(f\"KL Loss: {(kl_style + kl_content).item():.4f}\")\n",
    "            print(f\"Style Loss: {loss_multi_task.item():.4f}\")\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"\\nCompleted epoch. Average loss: {avg_loss:.4f}\")\n",
    "    return avg_loss\n",
    "\n",
    "# Training parameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "style_dim = 32\n",
    "content_dim = 256\n",
    "learning_rate = 5e-4\n",
    "epochs = 10\n",
    "\n",
    "# Initialize model and optimizer\n",
    "vae = DisentangledVAE(vocab_size, embedding_dim, hidden_dim, style_dim, content_dim).to(device)\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "\n",
    "print(f\"Starting training for {epochs} epochs...\")\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    print(\"-\" * 50)\n",
    "    loss = train_vae_with_dataset(vae, optimizer, data_loader, device)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleClassifier(nn.Module):\n",
    "    def _init_(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(StyleClassifier, self)._init_()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.encoder = nn.GRU(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, hidden = self.encoder(x)\n",
    "        # Combine bidirectional states\n",
    "        hidden = torch.cat([hidden[-2], hidden[-1]], dim=1)\n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UPDATED PART ABOVE, NOT UPDATED PART BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vae, 'model_complete.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_146017/3363134432.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_1 = torch.load('model_complete.pth')\n"
     ]
    }
   ],
   "source": [
    "model_1 = torch.load('model_complete.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: \t\t\t ever since joes has changed hands it 's just gotten worse and worse .\n",
      "Reconstructed Sentence: \t\t ever since joes has changed hands it 's just gotten worse and worse . tasting\n",
      "\n",
      "Original Sentence: \t\t\t there is definitely not enough room in that part of the venue .\n",
      "Reconstructed Sentence: \t\t there is definitely not enough room in that part of the venue . tasting tasting\n",
      "\n",
      "Original Sentence: \t\t\t so basically tasted watered down .\n",
      "Reconstructed Sentence: \t\t so basically tasted watered down . tasting tasting tasting tasting tasting tasting tasting tasting tasting\n",
      "\n",
      "Original Sentence: \t\t\t she said she 'd be back and disappeared for a few minutes .\n",
      "Reconstructed Sentence: \t\t she said she 'd be back and disappeared for a few minutes . tasting joining\n",
      "\n",
      "Original Sentence: \t\t\t i ca n't believe how inconsiderate this pharmacy is .\n",
      "Reconstructed Sentence: \t\t i ca n't believe how inconsiderate this pharmacy is . tasting joining joining joining joining\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Inspect some sentences from the data loader \n",
    "model_1.eval()\n",
    "with torch.no_grad():\n",
    "    for input_tokens, _, lengths in data_loader_test:\n",
    "        input_tokens = input_tokens.to(device)\n",
    "        x_reconstructed, _, _, _, _, _, _  = model_1(input_tokens)\n",
    "        x_reconstructed = x_reconstructed.argmax(dim=-1)  # Get the predicted token IDs\n",
    "\n",
    "        # Print a few input and output sentences\n",
    "        for i in range(5):  # Print 5 examples\n",
    "            original_sentence = tokens_to_words(input_tokens[i].tolist(), vocab)\n",
    "            reconstructed_sentence = tokens_to_words(x_reconstructed[i].tolist(), vocab)\n",
    "\n",
    "            print(\"Original Sentence: \\t\\t\\t\", \" \".join(original_sentence))\n",
    "            print(\"Reconstructed Sentence: \\t\\t\", \" \".join(reconstructed_sentence))\n",
    "            print()\n",
    "\n",
    "        break  # Only inspect the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_style_classifier(data_loader, vocab_size, device):\n",
    "    classifier = StyleClassifier(vocab_size, 300, 128).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "    classifier.train()\n",
    "    for epoch in range(20):  # Train for a few epochs\n",
    "        total_loss = 0\n",
    "        for input_tokens, labels, _ in data_loader:  # Adjusted to unpack three values\n",
    "            input_tokens = input_tokens.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predictions = classifier(input_tokens)\n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/5, Loss: {total_loss / len(data_loader)}\")\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "def evaluate_style_transfer(data_loader, model, classifier, device):\n",
    "    model.eval()\n",
    "    classifier.eval()\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_tokens, labels, _ in data_loader:\n",
    "            input_tokens = input_tokens.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Get the reconstructed sentences\n",
    "            x_reconstructed, _, _, _, _, _, _ = model(input_tokens)\n",
    "            x_reconstructed = x_reconstructed.argmax(dim=-1)\n",
    "\n",
    "            # Predict the style of the reconstructed sentences\n",
    "            style_predictions = classifier(x_reconstructed)\n",
    "            style_labels = (style_predictions > 0.5).float()\n",
    "            \n",
    "            correct_predictions += (style_labels == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(f\"Style Transfer Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m classifier \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_style_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m evaluate_style_transfer(data_loader_test, model_1, classifier, device)\n",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m, in \u001b[0;36mtrain_style_classifier\u001b[0;34m(data_loader, vocab_size, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):  \u001b[38;5;66;03m# Train for a few epochs\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m input_tokens, labels, _ \u001b[38;5;129;01min\u001b[39;00m data_loader:  \u001b[38;5;66;03m# Adjusted to unpack three values\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         input_tokens \u001b[38;5;241m=\u001b[39m input_tokens\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m         labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m, in \u001b[0;36mcollate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     15\u001b[0m padded_inputs \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mcat([seq, torch\u001b[38;5;241m.\u001b[39mzeros(max_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(seq), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)]) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[1;32m     16\u001b[0m lengths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(padded_inputs), \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m, lengths\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier = train_style_classifier(data_loader, len(vocab), device)\n",
    "evaluate_style_transfer(data_loader_test, model_1, classifier, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/qik/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Style Classifier...\n",
      "\n",
      "Epoch 1/5, Loss: 0.0954\n",
      "Epoch 2/5, Loss: 0.0522\n",
      "Epoch 3/5, Loss: 0.0387\n",
      "Epoch 4/5, Loss: 0.0300\n",
      "Epoch 5/5, Loss: 0.0241\n",
      "Epoch 6/5, Loss: 0.0205\n",
      "Epoch 7/5, Loss: 0.0178\n",
      "Epoch 8/5, Loss: 0.0158\n",
      "Epoch 9/5, Loss: 0.0145\n",
      "Epoch 10/5, Loss: 0.0139\n",
      "Epoch 11/5, Loss: 0.0132\n",
      "Epoch 12/5, Loss: 0.0124\n",
      "Epoch 13/5, Loss: 0.0116\n",
      "Epoch 14/5, Loss: 0.0117\n",
      "Epoch 15/5, Loss: 0.0116\n",
      "Epoch 16/5, Loss: 0.0113\n",
      "Epoch 17/5, Loss: 0.0113\n",
      "Epoch 18/5, Loss: 0.0108\n",
      "Epoch 19/5, Loss: 0.0105\n",
      "Epoch 20/5, Loss: 0.0104\n",
      "\n",
      "--- BLEU-S Score (Content Preservation) ---\n",
      "\n",
      "BLEU-S: Evaluating content preservation...\n",
      "\n",
      "Original: at this location the service was terrible .\n",
      "Reconstructed: so brand scale crumbs crappy steady shogun shogun adds adds adds adds adds adds adds\n",
      "\n",
      "Original: i ordered garlic bread and fettuccine alfredo pasta with vegetables .\n",
      "Reconstructed: anyways a+ cancer crusted cancer middle towing crusted middle watered belgian camarones inspector inspector inspector\n",
      "\n",
      "Original: i did n't even eat it .\n",
      "Reconstructed: warranties diamonds fusion covers masseuse increased winner volunteers volunteers volunteers inspector inspector inspector inspector inspector\n",
      "\n",
      "Original: this is a golf course that is tucked away it is in great condition .\n",
      "Reconstructed: renee renee renee nadine weekend dead renee renee tim liquid kitschy renee renee sites cause\n",
      "\n",
      "Original: the new management team is horrible !\n",
      "Reconstructed: a1 flagged active robbed marks marks kidding kidding noodle versus versus versus versus versus versus\n",
      "\n",
      "Average BLEU-S Score: 0.0000\n",
      "\n",
      "--- Style Transfer Accuracy ---\n",
      "\n",
      "Evaluating Style Transfer Accuracy...\n",
      "\n",
      "Original: the chips and guacamole were excellent too !\n",
      "Reconstructed: starts starts mm mm randomly sees struck mm niece victor victor victor victor victor saturday\n",
      "Style Prediction: 1.0, True Style: 1.0\n",
      "\n",
      "Original: but it may not actually be in stock anyway .\n",
      "Reconstructed: just ohhh domino incompetence attempted lion ohhh litchfield men picked picked elevators elevators elevators elevators\n",
      "Style Prediction: 0.0, True Style: 0.0\n",
      "\n",
      "Original: they also have lost sight of what good deli food is .\n",
      "Reconstructed: pairs people stars jewlery facilities forthright foundation fred rex facilities styrofoam plain selling proof proof\n",
      "Style Prediction: 0.0, True Style: 0.0\n",
      "\n",
      "Original: if i was the manager , i 'd fire that kid on the spot .\n",
      "Reconstructed: charts carr delighted brick beverage biscotti smell lucked cassie veterinarians restaraunt restaraunt glendale reliable styling\n",
      "Style Prediction: 1.0, True Style: 0.0\n",
      "\n",
      "Original: the food here is bland and boring and bad .\n",
      "Reconstructed: tummy represent assist dressy dressy vegetarian tl cucumber vegetarian vegetarian bananas cause cause cause cause\n",
      "Style Prediction: 1.0, True Style: 0.0\n",
      "\n",
      "Style Transfer Accuracy: 0.5469\n",
      "\n",
      "--- Final Results ---\n",
      "BLEU-S Score: 0.0000\n",
      "Style Transfer Accuracy: 0.5469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.546875)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### updated code \n",
    "import torch\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def tokens_to_words(token_ids, vocab):\n",
    "    inv_vocab = {v: k for k, v in vocab.items()}\n",
    "    return [inv_vocab.get(token_id, '<UNK>') for token_id in token_ids if token_id != 0]\n",
    "\n",
    "def calculate_bleu_score(data_loader, model, vocab, device):\n",
    "    model.eval()\n",
    "    total_bleu_score = 0\n",
    "    num_sentences = 0\n",
    "    smoothing_fn = SmoothingFunction().method1\n",
    "\n",
    "    print(\"\\nBLEU-S: Evaluating content preservation...\\n\")\n",
    "    with torch.no_grad():\n",
    "        for input_tokens, _, lengths in data_loader:\n",
    "            input_tokens = input_tokens.to(device)\n",
    "            x_reconstructed, _, _, _ = model(input_tokens)\n",
    "            x_reconstructed = x_reconstructed.argmax(dim=-1)\n",
    "\n",
    "            for i in range(min(5, len(input_tokens))):  \n",
    "                original_sentence = tokens_to_words(input_tokens[i].tolist(), vocab)\n",
    "                reconstructed_sentence = tokens_to_words(x_reconstructed[i].tolist(), vocab)\n",
    "                print(f\"Original: {' '.join(original_sentence)}\")\n",
    "                print(f\"Reconstructed: {' '.join(reconstructed_sentence)}\\n\")\n",
    "\n",
    "                bleu_score = sentence_bleu([original_sentence], reconstructed_sentence, smoothing_function=smoothing_fn)\n",
    "                total_bleu_score += bleu_score\n",
    "                num_sentences += 1\n",
    "\n",
    "            break  # Evaluate only on the first batch for now\n",
    "\n",
    "    avg_bleu_score = total_bleu_score / num_sentences if num_sentences > 0 else 0\n",
    "    print(f\"Average BLEU-S Score: {avg_bleu_score:.4f}\")\n",
    "    return avg_bleu_score\n",
    "\n",
    "def train_style_classifier(data_loader, vocab_size, device):\n",
    "    classifier = StyleClassifier(vocab_size, 300, 128).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "    classifier.train()\n",
    "    print(\"\\nTraining Style Classifier...\\n\")\n",
    "    for epoch in range(20):\n",
    "        total_loss = 0\n",
    "        for input_tokens, labels, _ in data_loader:\n",
    "            input_tokens = input_tokens.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predictions = classifier(input_tokens)\n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/5, Loss: {total_loss / len(data_loader):.4f}\")\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "def evaluate_style_transfer(data_loader, model, classifier, vocab, device):\n",
    "    model.eval()\n",
    "    classifier.eval()\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    print(\"\\nEvaluating Style Transfer Accuracy...\\n\")\n",
    "    with torch.no_grad():\n",
    "        for input_tokens, labels, _ in data_loader:\n",
    "            input_tokens = input_tokens.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            x_reconstructed, _, _, _ = model(input_tokens)\n",
    "            x_reconstructed = x_reconstructed.argmax(dim=-1)\n",
    "\n",
    "            style_predictions = classifier(x_reconstructed)\n",
    "            style_labels = (style_predictions > 0.5).float()\n",
    "            correct_predictions += (style_labels == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "            for i in range(min(5, len(input_tokens))):\n",
    "                original_sentence = tokens_to_words(input_tokens[i].tolist(), vocab)\n",
    "                reconstructed_sentence = tokens_to_words(x_reconstructed[i].tolist(), vocab)\n",
    "                print(f\"Original: {' '.join(original_sentence)}\")\n",
    "                print(f\"Reconstructed: {' '.join(reconstructed_sentence)}\")\n",
    "                print(f\"Style Prediction: {style_labels[i].item()}, True Style: {labels[i].item()}\\n\")\n",
    "\n",
    "            break  # Evaluate only on the first batch for now\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    print(f\"Style Transfer Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n",
    "\n",
    "def run_evaluation(data_loader_train, data_loader_test, model, vocab, vocab_size, device):\n",
    "    # Train Style Classifier\n",
    "    classifier = train_style_classifier(data_loader_train, vocab_size, device)\n",
    "\n",
    "    print(\"\\n--- BLEU-S Score (Content Preservation) ---\")\n",
    "    bleu_score = calculate_bleu_score(data_loader_test, model, vocab, device)\n",
    "\n",
    "    print(\"\\n--- Style Transfer Accuracy ---\")\n",
    "    style_transfer_accuracy = evaluate_style_transfer(data_loader_test, model, classifier, vocab, device)\n",
    "\n",
    "    print(\"\\n--- Final Results ---\")\n",
    "    print(f\"BLEU-S Score: {bleu_score:.4f}\")\n",
    "    print(f\"Style Transfer Accuracy: {style_transfer_accuracy:.4f}\")\n",
    "\n",
    "    return bleu_score, style_transfer_accuracy\n",
    "\n",
    "run_evaluation(data_loader, data_loader_test, model, vocab, len(vocab), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "for a, b, c in data_loader:\n",
    "    for i in a:\n",
    "        print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
