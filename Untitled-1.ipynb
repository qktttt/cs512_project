{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm  \n",
    "from dataloader import *\n",
    "from model import * \n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import nltk\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs, labels = zip(*batch)\n",
    "    max_length = max(len(seq) for seq in inputs)\n",
    "    \n",
    "    # Convert each sequence to a list, pad with 0, and convert to tensor\n",
    "    padded_inputs = [torch.cat([seq, torch.zeros(max_length - len(seq), dtype=torch.long)]) for seq in inputs]\n",
    "    lengths = [len(seq) for seq in inputs]\n",
    "    \n",
    "    return torch.stack(padded_inputs), torch.tensor(labels, dtype=torch.float), lengths\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "target_confidence = 0.8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "data_dir = \"./data/sentiment_style_transfer/yelp\"\n",
    "vocab = build_vocab(data_dir)\n",
    "dataset = TextDataset(data_dir, vocab)\n",
    "data_loader = DataLoader(dataset, batch_size=64, collate_fn=collate_fn, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = StyleTransferModel(len(vocab), 300, 256, 16, 128).to(device)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 6926/6926 [05:34<00:00, 20.72batch/s, loss=0.618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 completed. Average Loss: 0.6183889831284934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 6926/6926 [05:37<00:00, 20.50batch/s, loss=0.229] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 completed. Average Loss: 0.22921297018383416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 6926/6926 [05:34<00:00, 20.71batch/s, loss=0.299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 completed. Average Loss: 0.2993834251228307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 6926/6926 [05:33<00:00, 20.77batch/s, loss=0.224] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 completed. Average Loss: 0.22419913678819037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 6926/6926 [05:29<00:00, 21.01batch/s, loss=0.616] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 completed. Average Loss: 0.6160696460356646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 6926/6926 [05:30<00:00, 20.96batch/s, loss=0.33]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 completed. Average Loss: 0.329525139434294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 6926/6926 [05:35<00:00, 20.62batch/s, loss=0.279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 completed. Average Loss: 0.2789108553194553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 6926/6926 [05:34<00:00, 20.73batch/s, loss=0.391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 completed. Average Loss: 0.3910796397221144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 6926/6926 [05:30<00:00, 20.93batch/s, loss=0.348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 completed. Average Loss: 0.34840153873824936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 6926/6926 [05:25<00:00, 21.27batch/s, loss=0.251]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 completed. Average Loss: 0.2513471563543881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm(data_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\")\n",
    "    \n",
    "    for input_tokens, labels, lengths in progress_bar:\n",
    "        input_tokens = input_tokens.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_reconstructed, style_mean, content_mean, s_prime = model(input_tokens, target_confidence)\n",
    "        style_logvar = torch.zeros_like(style_mean)\n",
    "        content_logvar = torch.zeros_like(content_mean)\n",
    "        loss = vae_loss(x_reconstructed, input_tokens, style_mean, style_logvar, content_mean, content_logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Update the progress bar with the current loss\n",
    "        progress_bar.set_postfix(loss=epoch_loss / (progress_bar.n + 1))\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} completed. Average Loss: {epoch_loss / len(data_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_complete.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85066/3363134432.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_1 = torch.load('model_complete.pth')\n"
     ]
    }
   ],
   "source": [
    "model_1 = torch.load('model_complete.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "class TextDatasetTest(Dataset):\n",
    "    def __init__(self, data_dir, vocab):\n",
    "        super(TextDatasetTest, self).__init__()\n",
    "        self.data = []\n",
    "        self.vocab = vocab\n",
    "\n",
    "        # Load data from the files\n",
    "        files = [\"sentiment.test.0\", \"sentiment.test.1\"]\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(data_dir, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    tokens = line.strip().split()\n",
    "                    label = 1 if filename.endswith('.1') else 0  # Binary label\n",
    "                    self.data.append((tokens, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens, label = self.data[idx]\n",
    "        token_ids = [self.vocab.get(token, self.vocab['<UNK>']) for token in tokens]\n",
    "        return torch.tensor(token_ids, dtype=torch.long), torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab(data_dir)\n",
    "dataset = TextDatasetTest(data_dir, vocab)\n",
    "data_loader_test = DataLoader(dataset, batch_size=64, collate_fn=collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/qik/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', \"'s\", 'not', 'much', 'like', 'an', 'actual', 'irish', 'pub', ',', 'which', 'is', 'depressing', '.'] ['it', \"'s\", 'not', 'much', 'like', 'an', 'actual', 'irish', 'pub', ',', 'which', 'is', 'depressing', '.']\n",
      "['definitely', 'a', 'must', 'do', 'if', 'you', 'have', 'time', 'in', 'the', 'phoenix', 'area', '.'] ['definitely', 'a', 'must', 'do', 'if', 'you', 'have', 'time', 'in', 'the', 'phoenix', 'area', '.']\n",
      "['my', 'plate', 'looked', 'nearly', 'half', 'empty', 'except', 'for', 'the', 'small', 'container', 'of', 'cole', 'slaw', '.'] ['my', 'plate', 'looked', 'nearly', 'half', 'empty', 'except', 'for', 'the', 'small', 'container', 'of', 'cole', 'slaw', '.']\n",
      "['very', 'good', 'brunch', ',', 'was', 'impressed', 'with', 'selection', 'and', 'quality', '.'] ['very', 'good', 'brunch', ',', 'was', 'impressed', 'with', 'selection', 'and', 'quality', '.']\n",
      "['always', 'a', 'great', 'experience', 'there', 'with', 'the', 'owner', 'and', 'the', 'rest', 'of', 'the', 'team', '.'] ['always', 'a', 'great', 'experience', 'there', 'with', 'the', 'owner', 'and', 'the', 'rest', 'of', 'the', 'team', '.']\n",
      "['the', 'adovada', 'is', 'hot', 'but', 'wonderful', 'and', 'the', 'chocolate', 'bread', 'pudding', 'is', 'amazing', '.'] ['the', 'adovada', 'is', 'hot', 'but', 'wonderful', 'and', 'the', 'chocolate', 'bread', 'pudding', 'is', 'amazing', '.']\n",
      "['i', \"'ll\", 'keep', 'looking', 'for', 'a', 'different', 'salon', '.'] ['i', \"'ll\", 'keep', 'looking', 'for', 'a', 'different', 'salon', '.']\n",
      "['it', \"'s\", 'a', 'big', 'bowl', 'of', 'sweet', 'happiness', '.'] ['it', \"'s\", 'a', 'big', 'bowl', 'of', 'sweet', 'happiness', '.']\n",
      "['but', 'being', 'a', 'tucson', 'native', 'this', 'place', 'brought', 'nostalgia', 'via', 'my', 'tastebuds', '.'] ['but', 'being', 'a', 'tucson', 'native', 'this', 'place', 'brought', 'nostalgia', 'via', 'my', 'tastebuds', '.']\n",
      "['thorough', ',', 'reasonably', 'priced', 'and', 'they', 'answer', 'the', 'phone', 'when', 'called', 'promptly', '.'] ['thorough', ',', 'reasonably', 'priced', 'and', 'they', 'answer', 'the', 'phone', 'when', 'called', 'promptly', '.']\n",
      "Average BLEU Score: 0.9990\n"
     ]
    }
   ],
   "source": [
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to convert token IDs back to words using the vocabulary\n",
    "def tokens_to_words(token_ids, vocab):\n",
    "    inv_vocab = {v: k for k, v in vocab.items()}\n",
    "    return [inv_vocab.get(token_id, '<UNK>') for token_id in token_ids if token_id != 0]  # Exclude padding\n",
    "\n",
    "# Function to calculate BLEU score for a batch\n",
    "def calculate_bleu_score(data_loader, model, vocab, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_bleu_score = 0\n",
    "    num_sentences = 0\n",
    "    \n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for input_tokens, _, lengths in data_loader:\n",
    "            input_tokens = input_tokens.to(device)\n",
    "            x_reconstructed, _, _, _ = model(input_tokens)\n",
    "            x_reconstructed = x_reconstructed.argmax(dim=-1)  # Get the predicted token IDs\n",
    "\n",
    "            # Calculate BLEU score for each sentence\n",
    "            for i in range(len(input_tokens)):\n",
    "                original_sentence = tokens_to_words(input_tokens[i].tolist(), vocab)\n",
    "                reconstructed_sentence = tokens_to_words(x_reconstructed[i].tolist(), vocab)\n",
    "\n",
    "                counter += 1\n",
    "                if counter % 100 == 0:\n",
    "                    print(original_sentence, reconstructed_sentence)\n",
    "                # Calculate BLEU score\n",
    "                bleu_score = sentence_bleu([original_sentence], reconstructed_sentence)\n",
    "                total_bleu_score += bleu_score\n",
    "                num_sentences += 1\n",
    "\n",
    "    # Return the average BLEU score\n",
    "    return total_bleu_score / num_sentences if num_sentences > 0 else 0\n",
    "\n",
    "# Calculate the BLEU score\n",
    "bleu_score = calculate_bleu_score(data_loader_test, model_1, vocab, device)\n",
    "print(f\"Average BLEU Score: {bleu_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence:  the crew was very friendly and accommodating .\n",
      "Reconstructed Sentence:  the crew was very friendly and accommodating .\n",
      "\n",
      "Original Sentence:  the best bar in town .\n",
      "Reconstructed Sentence:  the best bar in town .\n",
      "\n",
      "Original Sentence:  he always looks gorgeous and is so happy when i pick him up !\n",
      "Reconstructed Sentence:  he always looks gorgeous and is so happy when i pick him up !\n",
      "\n",
      "Original Sentence:  blue cheese dressing was n't the best by any means .\n",
      "Reconstructed Sentence:  blue cheese dressing was n't the best by any means .\n",
      "\n",
      "Original Sentence:  the building itself looks abandoned .\n",
      "Reconstructed Sentence:  the building itself looks abandoned .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def tokens_to_words(token_ids, vocab):\n",
    "    inv_vocab = {v: k for k, v in vocab.items()}\n",
    "    return [inv_vocab.get(token_id, '<UNK>') for token_id in token_ids if token_id != 0]  # Exclude padding\n",
    "\n",
    "# Inspect some sentences from the data loader\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for input_tokens, _, lengths in data_loader_test:\n",
    "        input_tokens = input_tokens.to(device)\n",
    "        x_reconstructed, _, _, _ = model_1(input_tokens)\n",
    "        x_reconstructed = x_reconstructed.argmax(dim=-1)  # Get the predicted token IDs\n",
    "\n",
    "        # Print a few input and output sentences\n",
    "        for i in range(5):  # Print 5 examples\n",
    "            original_sentence = tokens_to_words(input_tokens[i].tolist(), vocab)\n",
    "            reconstructed_sentence = tokens_to_words(x_reconstructed[i].tolist(), vocab)\n",
    "\n",
    "            print(\"Original Sentence: \", \" \".join(original_sentence))\n",
    "            print(\"Reconstructed Sentence: \", \" \".join(reconstructed_sentence))\n",
    "            print()\n",
    "\n",
    "        break  # Only inspect the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Style Classifier\n",
    "class StyleClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super(StyleClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, h = self.rnn(x)\n",
    "        h = h[-1]  # Take the last hidden state\n",
    "        output = self.fc(h)\n",
    "        return self.sigmoid(output).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<UNK>': 1,\n",
       " '.': 2,\n",
       " 'the': 3,\n",
       " 'and': 4,\n",
       " 'i': 5,\n",
       " '!': 6,\n",
       " ',': 7,\n",
       " 'is': 8,\n",
       " 'was': 9,\n",
       " 'a': 10,\n",
       " 'to': 11,\n",
       " 'it': 12,\n",
       " 'this': 13,\n",
       " 'great': 14,\n",
       " 'food': 15,\n",
       " 'for': 16,\n",
       " 'place': 17,\n",
       " 'service': 18,\n",
       " 'good': 19,\n",
       " 'of': 20,\n",
       " 'my': 21,\n",
       " 'in': 22,\n",
       " 'very': 23,\n",
       " 'they': 24,\n",
       " 'are': 25,\n",
       " 'not': 26,\n",
       " '_num_': 27,\n",
       " 'with': 28,\n",
       " 'you': 29,\n",
       " \"n't\": 30,\n",
       " 'have': 31,\n",
       " \"'s\": 32,\n",
       " 'we': 33,\n",
       " 'that': 34,\n",
       " 'so': 35,\n",
       " 'here': 36,\n",
       " 'love': 37,\n",
       " 'but': 38,\n",
       " 'had': 39,\n",
       " 'friendly': 40,\n",
       " 'best': 41,\n",
       " 'were': 42,\n",
       " 'always': 43,\n",
       " 'staff': 44,\n",
       " 'on': 45,\n",
       " 'be': 46,\n",
       " 'at': 47,\n",
       " 'all': 48,\n",
       " 'will': 49,\n",
       " 'really': 50,\n",
       " 'back': 51,\n",
       " 'there': 52,\n",
       " 'nice': 53,\n",
       " 'just': 54,\n",
       " 'no': 55,\n",
       " 'as': 56,\n",
       " 'me': 57,\n",
       " 'do': 58,\n",
       " 'their': 59,\n",
       " 'amazing': 60,\n",
       " 'recommend': 61,\n",
       " 'time': 62,\n",
       " 'would': 63,\n",
       " 'our': 64,\n",
       " 'one': 65,\n",
       " 'delicious': 66,\n",
       " 'definitely': 67,\n",
       " 'experience': 68,\n",
       " 'like': 69,\n",
       " 'out': 70,\n",
       " 'well': 71,\n",
       " 'also': 72,\n",
       " 'did': 73,\n",
       " 'she': 74,\n",
       " 'go': 75,\n",
       " 'ever': 76,\n",
       " 'excellent': 77,\n",
       " 'too': 78,\n",
       " 'get': 79,\n",
       " 'has': 80,\n",
       " 'customer': 81,\n",
       " 'an': 82,\n",
       " 'if': 83,\n",
       " 'been': 84,\n",
       " 'he': 85,\n",
       " 'what': 86,\n",
       " 'again': 87,\n",
       " \"'ve\": 88,\n",
       " 'from': 89,\n",
       " 'even': 90,\n",
       " 'fresh': 91,\n",
       " 'your': 92,\n",
       " '...': 93,\n",
       " 'up': 94,\n",
       " 'awesome': 95,\n",
       " 'never': 96,\n",
       " 'pizza': 97,\n",
       " 'restaurant': 98,\n",
       " 'highly': 99,\n",
       " 'clean': 100,\n",
       " 'them': 101,\n",
       " 'prices': 102,\n",
       " 'favorite': 103,\n",
       " 'about': 104,\n",
       " 'bad': 105,\n",
       " 'got': 106,\n",
       " '?': 107,\n",
       " '$': 108,\n",
       " 'people': 109,\n",
       " 'or': 110,\n",
       " 'worst': 111,\n",
       " 'pretty': 112,\n",
       " 'could': 113,\n",
       " 'worth': 114,\n",
       " 'everything': 115,\n",
       " 'when': 116,\n",
       " \"'m\": 117,\n",
       " 'atmosphere': 118,\n",
       " 'by': 119,\n",
       " 'location': 120,\n",
       " 'chicken': 121,\n",
       " 'can': 122,\n",
       " 'horrible': 123,\n",
       " 'price': 124,\n",
       " 'going': 125,\n",
       " 'happy': 126,\n",
       " 'some': 127,\n",
       " 'only': 128,\n",
       " 'wonderful': 129,\n",
       " 'super': 130,\n",
       " 'much': 131,\n",
       " 'more': 132,\n",
       " 'us': 133,\n",
       " 'better': 134,\n",
       " 'helpful': 135,\n",
       " 'work': 136,\n",
       " 'fast': 137,\n",
       " 'fantastic': 138,\n",
       " 'went': 139,\n",
       " 'ordered': 140,\n",
       " 'first': 141,\n",
       " 'quality': 142,\n",
       " 'lunch': 143,\n",
       " 'family': 144,\n",
       " 'come': 145,\n",
       " ')': 146,\n",
       " 'bar': 147,\n",
       " 'store': 148,\n",
       " 'terrible': 149,\n",
       " '&': 150,\n",
       " 'selection': 151,\n",
       " 'absolutely': 152,\n",
       " 'made': 153,\n",
       " 'rude': 154,\n",
       " 'little': 155,\n",
       " 'new': 156,\n",
       " 'order': 157,\n",
       " 'after': 158,\n",
       " 'over': 159,\n",
       " 'than': 160,\n",
       " 'other': 161,\n",
       " 'minutes': 162,\n",
       " 'job': 163,\n",
       " 'right': 164,\n",
       " 'way': 165,\n",
       " 'nothing': 166,\n",
       " 'give': 167,\n",
       " 'eat': 168,\n",
       " 'everyone': 169,\n",
       " 'thank': 170,\n",
       " 'came': 171,\n",
       " 'fun': 172,\n",
       " 'wait': 173,\n",
       " 'every': 174,\n",
       " 'am': 175,\n",
       " '-': 176,\n",
       " 'loved': 177,\n",
       " 'which': 178,\n",
       " 'perfect': 179,\n",
       " 'still': 180,\n",
       " 'any': 181,\n",
       " 'disappointed': 182,\n",
       " 'off': 183,\n",
       " 'tasty': 184,\n",
       " 'how': 185,\n",
       " 'make': 186,\n",
       " 'thanks': 187,\n",
       " 'stars': 188,\n",
       " 'breakfast': 189,\n",
       " \"''\": 190,\n",
       " 'down': 191,\n",
       " 'her': 192,\n",
       " 'menu': 193,\n",
       " 'business': 194,\n",
       " 'spot': 195,\n",
       " 'money': 196,\n",
       " '(': 197,\n",
       " 'sushi': 198,\n",
       " 'care': 199,\n",
       " 'extremely': 200,\n",
       " 'hot': 201,\n",
       " 'night': 202,\n",
       " 'said': 203,\n",
       " '``': 204,\n",
       " 'both': 205,\n",
       " 'overall': 206,\n",
       " 'take': 207,\n",
       " 'because': 208,\n",
       " 'know': 209,\n",
       " 'around': 210,\n",
       " 'town': 211,\n",
       " 'most': 212,\n",
       " 'does': 213,\n",
       " 'another': 214,\n",
       " 'professional': 215,\n",
       " 'salad': 216,\n",
       " 'say': 217,\n",
       " 'then': 218,\n",
       " 'quick': 219,\n",
       " 'day': 220,\n",
       " 'meal': 221,\n",
       " 'these': 222,\n",
       " 'now': 223,\n",
       " 'coming': 224,\n",
       " \"'ll\": 225,\n",
       " 'sauce': 226,\n",
       " 'feel': 227,\n",
       " 'car': 228,\n",
       " 'his': 229,\n",
       " 'reasonable': 230,\n",
       " 'try': 231,\n",
       " 'times': 232,\n",
       " 'sure': 233,\n",
       " 'guys': 234,\n",
       " 'area': 235,\n",
       " 'shop': 236,\n",
       " 'two': 237,\n",
       " 'drinks': 238,\n",
       " 'dinner': 239,\n",
       " 'should': 240,\n",
       " 'big': 241,\n",
       " 'visit': 242,\n",
       " 'see': 243,\n",
       " 'cheese': 244,\n",
       " 'room': 245,\n",
       " 'why': 246,\n",
       " 'want': 247,\n",
       " 'its': 248,\n",
       " 'home': 249,\n",
       " 'far': 250,\n",
       " 'find': 251,\n",
       " 'took': 252,\n",
       " 'done': 253,\n",
       " 'special': 254,\n",
       " 'wo': 255,\n",
       " 'enjoyed': 256,\n",
       " 'such': 257,\n",
       " 'coffee': 258,\n",
       " 'found': 259,\n",
       " 'last': 260,\n",
       " \"'re\": 261,\n",
       " 'left': 262,\n",
       " 'flavor': 263,\n",
       " 'years': 264,\n",
       " 'sandwich': 265,\n",
       " 'anyone': 266,\n",
       " 'small': 267,\n",
       " 'old': 268,\n",
       " 'top': 269,\n",
       " 'who': 270,\n",
       " 'beer': 271,\n",
       " 'enjoy': 272,\n",
       " 'long': 273,\n",
       " 'before': 274,\n",
       " 'taste': 275,\n",
       " 'return': 276,\n",
       " 'mexican': 277,\n",
       " 'hour': 278,\n",
       " ':': 279,\n",
       " 'friends': 280,\n",
       " 'attentive': 281,\n",
       " 'many': 282,\n",
       " 'bread': 283,\n",
       " 'away': 284,\n",
       " 'server': 285,\n",
       " 'however': 286,\n",
       " 'beautiful': 287,\n",
       " 'decent': 288,\n",
       " 'tasted': 289,\n",
       " 'cool': 290,\n",
       " 'impressed': 291,\n",
       " 'kind': 292,\n",
       " 'huge': 293,\n",
       " 'sweet': 294,\n",
       " 'wrong': 295,\n",
       " 'poor': 296,\n",
       " 'thing': 297,\n",
       " 'ca': 298,\n",
       " 'vegas': 299,\n",
       " 'cold': 300,\n",
       " 'ok': 301,\n",
       " 'employees': 302,\n",
       " 'authentic': 303,\n",
       " 'office': 304,\n",
       " 'lot': 305,\n",
       " 'places': 306,\n",
       " 'awful': 307,\n",
       " 'check': 308,\n",
       " 'star': 309,\n",
       " 'rice': 310,\n",
       " 'wings': 311,\n",
       " 'though': 312,\n",
       " 'soup': 313,\n",
       " 'recommended': 314,\n",
       " 'anything': 315,\n",
       " 'fries': 316,\n",
       " 'something': 317,\n",
       " 'slow': 318,\n",
       " 'waitress': 319,\n",
       " 'next': 320,\n",
       " 'phoenix': 321,\n",
       " 'tried': 322,\n",
       " 'hotel': 323,\n",
       " 'being': 324,\n",
       " 'fried': 325,\n",
       " 'manager': 326,\n",
       " 'steak': 327,\n",
       " 'probably': 328,\n",
       " 'bland': 329,\n",
       " 'keep': 330,\n",
       " 'company': 331,\n",
       " 'look': 332,\n",
       " 'fish': 333,\n",
       " 'stay': 334,\n",
       " 'walked': 335,\n",
       " 'today': 336,\n",
       " 'chinese': 337,\n",
       " 'cooked': 338,\n",
       " 'local': 339,\n",
       " 'priced': 340,\n",
       " 'wow': 341,\n",
       " 'told': 342,\n",
       " 'outstanding': 343,\n",
       " 'meat': 344,\n",
       " 'portions': 345,\n",
       " 'quite': 346,\n",
       " 'waste': 347,\n",
       " 'looked': 348,\n",
       " 'think': 349,\n",
       " 'him': 350,\n",
       " 'kids': 351,\n",
       " 'pleasant': 352,\n",
       " 'else': 353,\n",
       " 'owner': 354,\n",
       " 'help': 355,\n",
       " 'looking': 356,\n",
       " 'need': 357,\n",
       " 'hours': 358,\n",
       " 'salsa': 359,\n",
       " 'use': 360,\n",
       " 'few': 361,\n",
       " 'enough': 362,\n",
       " 'honest': 363,\n",
       " 'beef': 364,\n",
       " 'disappointing': 365,\n",
       " 'especially': 366,\n",
       " 'same': 367,\n",
       " 'dry': 368,\n",
       " 'gave': 369,\n",
       " 'makes': 370,\n",
       " 'whole': 371,\n",
       " 'asked': 372,\n",
       " 'italian': 373,\n",
       " 'comfortable': 374,\n",
       " 'free': 375,\n",
       " 'easy': 376,\n",
       " 'call': 377,\n",
       " 'full': 378,\n",
       " 'cheap': 379,\n",
       " 'inside': 380,\n",
       " 'chips': 381,\n",
       " 'sandwiches': 382,\n",
       " 'customers': 383,\n",
       " 'drink': 384,\n",
       " 'burger': 385,\n",
       " 'later': 386,\n",
       " 'busy': 387,\n",
       " 'called': 388,\n",
       " 'deal': 389,\n",
       " 'hard': 390,\n",
       " 'shrimp': 391,\n",
       " 'high': 392,\n",
       " 'table': 393,\n",
       " 'while': 394,\n",
       " 'things': 395,\n",
       " 'side': 396,\n",
       " 'real': 397,\n",
       " 'pho': 398,\n",
       " 'wine': 399,\n",
       " 'avoid': 400,\n",
       " 'once': 401,\n",
       " 'actually': 402,\n",
       " 'bit': 403,\n",
       " 'knowledgeable': 404,\n",
       " 'husband': 405,\n",
       " 'almost': 406,\n",
       " 'lots': 407,\n",
       " 'rolls': 408,\n",
       " 'large': 409,\n",
       " 'charlotte': 410,\n",
       " 'where': 411,\n",
       " 'totally': 412,\n",
       " 'thai': 413,\n",
       " 'salon': 414,\n",
       " 'dirty': 415,\n",
       " 'tacos': 416,\n",
       " 'mediocre': 417,\n",
       " 'into': 418,\n",
       " 'used': 419,\n",
       " 'worse': 420,\n",
       " 'must': 421,\n",
       " 'either': 422,\n",
       " 'spicy': 423,\n",
       " 'different': 424,\n",
       " 'oh': 425,\n",
       " 'guy': 426,\n",
       " 'since': 427,\n",
       " 'completely': 428,\n",
       " 'getting': 429,\n",
       " 'gross': 430,\n",
       " 'dishes': 431,\n",
       " 'plus': 432,\n",
       " 'wife': 433,\n",
       " \"'d\": 434,\n",
       " 'front': 435,\n",
       " 'gem': 436,\n",
       " 'wish': 437,\n",
       " 'zero': 438,\n",
       " 'disgusting': 439,\n",
       " 'delivery': 440,\n",
       " 'waiting': 441,\n",
       " 'problem': 442,\n",
       " 'stuff': 443,\n",
       " 'life': 444,\n",
       " 'options': 445,\n",
       " 'efficient': 446,\n",
       " 'reviews': 447,\n",
       " 'part': 448,\n",
       " 'unfortunately': 449,\n",
       " 'open': 450,\n",
       " 'friend': 451,\n",
       " 'maybe': 452,\n",
       " 'items': 453,\n",
       " 'valley': 454,\n",
       " 'looks': 455,\n",
       " 'dining': 456,\n",
       " 'truly': 457,\n",
       " 'house': 458,\n",
       " 'drive': 459,\n",
       " 'neighborhood': 460,\n",
       " 'through': 461,\n",
       " 'restaurants': 462,\n",
       " 'received': 463,\n",
       " 'warm': 464,\n",
       " 'hair': 465,\n",
       " 'waited': 466,\n",
       " 'course': 467,\n",
       " 'specials': 468,\n",
       " 'eating': 469,\n",
       " 'put': 470,\n",
       " 'pittsburgh': 471,\n",
       " 'needs': 472,\n",
       " 'seriously': 473,\n",
       " 'week': 474,\n",
       " 'leave': 475,\n",
       " 'let': 476,\n",
       " 'fan': 477,\n",
       " 'incredible': 478,\n",
       " 'perfectly': 479,\n",
       " 'yummy': 480,\n",
       " 'fair': 481,\n",
       " 'ridiculous': 482,\n",
       " 'burgers': 483,\n",
       " 'usually': 484,\n",
       " 'each': 485,\n",
       " 'value': 486,\n",
       " 'waiter': 487,\n",
       " 'music': 488,\n",
       " 'style': 489,\n",
       " 'point': 490,\n",
       " 'water': 491,\n",
       " 'tea': 492,\n",
       " 'stop': 493,\n",
       " 'cream': 494,\n",
       " 'sorry': 495,\n",
       " 'finally': 496,\n",
       " 'ice': 497,\n",
       " 'less': 498,\n",
       " 'tell': 499,\n",
       " 'cut': 500,\n",
       " 'working': 501,\n",
       " 'expensive': 502,\n",
       " 'run': 503,\n",
       " 'management': 504,\n",
       " 'variety': 505,\n",
       " 'consistently': 506,\n",
       " 'felt': 507,\n",
       " 'gets': 508,\n",
       " 'year': 509,\n",
       " 'review': 510,\n",
       " 'close': 511,\n",
       " 'pay': 512,\n",
       " 'dish': 513,\n",
       " 'second': 514,\n",
       " 'person': 515,\n",
       " 'ate': 516,\n",
       " 'thought': 517,\n",
       " 'without': 518,\n",
       " 'trip': 519,\n",
       " 'served': 520,\n",
       " 'bring': 521,\n",
       " 'entire': 522,\n",
       " 'liked': 523,\n",
       " 'hands': 524,\n",
       " 'days': 525,\n",
       " 'wanted': 526,\n",
       " 'outside': 527,\n",
       " 'decor': 528,\n",
       " 'extra': 529,\n",
       " 'flavorful': 530,\n",
       " 'okay': 531,\n",
       " 'live': 532,\n",
       " 'tables': 533,\n",
       " 'pork': 534,\n",
       " 'nails': 535,\n",
       " 'unique': 536,\n",
       " 'airport': 537,\n",
       " 'simple': 538,\n",
       " 'please': 539,\n",
       " 'late': 540,\n",
       " 'half': 541,\n",
       " 'beyond': 542,\n",
       " 'least': 543,\n",
       " 'solid': 544,\n",
       " 'comes': 545,\n",
       " 'pasta': 546,\n",
       " 'average': 547,\n",
       " 'someone': 548,\n",
       " 'cute': 549,\n",
       " 'soon': 550,\n",
       " 'notch': 551,\n",
       " 'seems': 552,\n",
       " 'phone': 553,\n",
       " 'affordable': 554,\n",
       " 'bbq': 555,\n",
       " 'gone': 556,\n",
       " 'fine': 557,\n",
       " 'several': 558,\n",
       " 'servers': 559,\n",
       " 'beans': 560,\n",
       " 'seem': 561,\n",
       " 'tonight': 562,\n",
       " 'brought': 563,\n",
       " 'simply': 564,\n",
       " 'line': 565,\n",
       " 'pleased': 566,\n",
       " 'guess': 567,\n",
       " 'parking': 568,\n",
       " 'owners': 569,\n",
       " 'ambiance': 570,\n",
       " 'seemed': 571,\n",
       " 'consistent': 572,\n",
       " 'regular': 573,\n",
       " 'empty': 574,\n",
       " 'three': 575,\n",
       " ';': 576,\n",
       " 'incredibly': 577,\n",
       " 'reason': 578,\n",
       " 'bill': 579,\n",
       " 'dog': 580,\n",
       " 'sad': 581,\n",
       " 'returning': 582,\n",
       " 'ask': 583,\n",
       " 'during': 584,\n",
       " 'yelp': 585,\n",
       " 'twice': 586,\n",
       " 'lady': 587,\n",
       " 'treat': 588,\n",
       " 'having': 589,\n",
       " 'egg': 590,\n",
       " 'believe': 591,\n",
       " 'end': 592,\n",
       " 'madison': 593,\n",
       " 'doing': 594,\n",
       " 'buy': 595,\n",
       " 'crust': 596,\n",
       " 'reasonably': 597,\n",
       " '--': 598,\n",
       " 'surprised': 599,\n",
       " 'doctor': 600,\n",
       " 'paid': 601,\n",
       " 'change': 602,\n",
       " 'choice': 603,\n",
       " 'ingredients': 604,\n",
       " 'rooms': 605,\n",
       " 'above': 606,\n",
       " 'date': 607,\n",
       " 'needed': 608,\n",
       " 'taco': 609,\n",
       " 'making': 610,\n",
       " 'appointment': 611,\n",
       " 'courteous': 612,\n",
       " 'attitude': 613,\n",
       " 'burrito': 614,\n",
       " 'kept': 615,\n",
       " 'roll': 616,\n",
       " 'buffet': 617,\n",
       " 'mistake': 618,\n",
       " 'salads': 619,\n",
       " 'fabulous': 620,\n",
       " 'start': 621,\n",
       " 'yet': 622,\n",
       " 'those': 623,\n",
       " 'size': 624,\n",
       " 'nail': 625,\n",
       " 'sat': 626,\n",
       " 'name': 627,\n",
       " 'environment': 628,\n",
       " 'charge': 629,\n",
       " 'ago': 630,\n",
       " 'quickly': 631,\n",
       " 'seating': 632,\n",
       " 'elsewhere': 633,\n",
       " 'hate': 634,\n",
       " 'total': 635,\n",
       " 'las': 636,\n",
       " 'dr.': 637,\n",
       " 'portion': 638,\n",
       " 'trying': 639,\n",
       " 'walk': 640,\n",
       " 'offer': 641,\n",
       " 'disappointment': 642,\n",
       " 'owned': 643,\n",
       " 'accommodating': 644,\n",
       " 'welcoming': 645,\n",
       " 'man': 646,\n",
       " 'greasy': 647,\n",
       " 'plenty': 648,\n",
       " 'often': 649,\n",
       " 'lost': 650,\n",
       " 'short': 651,\n",
       " 'loves': 652,\n",
       " 'instead': 653,\n",
       " 'arrived': 654,\n",
       " 'exceptional': 655,\n",
       " 'green': 656,\n",
       " 'seen': 657,\n",
       " 'hit': 658,\n",
       " 'until': 659,\n",
       " 'needless': 660,\n",
       " 'taking': 661,\n",
       " 'group': 662,\n",
       " 'sucks': 663,\n",
       " 'overpriced': 664,\n",
       " 'stayed': 665,\n",
       " 'negative': 666,\n",
       " 'true': 667,\n",
       " 'tastes': 668,\n",
       " 'helped': 669,\n",
       " 'yes': 670,\n",
       " 'choices': 671,\n",
       " 'couple': 672,\n",
       " 'treated': 673,\n",
       " 'team': 674,\n",
       " 'french': 675,\n",
       " 'patio': 676,\n",
       " 'absolute': 677,\n",
       " 'red': 678,\n",
       " 'morning': 679,\n",
       " 'counter': 680,\n",
       " 'packed': 681,\n",
       " 'oil': 682,\n",
       " 'potato': 683,\n",
       " 'cost': 684,\n",
       " 'stopped': 685,\n",
       " 'cake': 686,\n",
       " 'view': 687,\n",
       " 'brunch': 688,\n",
       " 'eaten': 689,\n",
       " 'door': 690,\n",
       " 'unprofessional': 691,\n",
       " 'hidden': 692,\n",
       " '%': 693,\n",
       " 'itself': 694,\n",
       " 'polite': 695,\n",
       " 'party': 696,\n",
       " 'works': 697,\n",
       " 'pool': 698,\n",
       " 'myself': 699,\n",
       " 'prepared': 700,\n",
       " 'garlic': 701,\n",
       " 'low': 702,\n",
       " 'bartender': 703,\n",
       " 'moved': 704,\n",
       " 'lovely': 705,\n",
       " 'recently': 706,\n",
       " 'amount': 707,\n",
       " 'patient': 708,\n",
       " 'establishment': 709,\n",
       " 'plate': 710,\n",
       " 'own': 711,\n",
       " 'shopping': 712,\n",
       " 'potatoes': 713,\n",
       " 'caring': 714,\n",
       " 'sunday': 715,\n",
       " 'meals': 716,\n",
       " 'glad': 717,\n",
       " 'eggs': 718,\n",
       " 'desk': 719,\n",
       " 'pricey': 720,\n",
       " 'smile': 721,\n",
       " 'seafood': 722,\n",
       " 'prompt': 723,\n",
       " 'appetizer': 724,\n",
       " 'city': 725,\n",
       " 'evening': 726,\n",
       " 'vibe': 727,\n",
       " 'phenomenal': 728,\n",
       " 'ordering': 729,\n",
       " 'nasty': 730,\n",
       " 'crab': 731,\n",
       " 'remember': 732,\n",
       " 'crispy': 733,\n",
       " 'wedding': 734,\n",
       " 'joint': 735,\n",
       " 'talk': 736,\n",
       " 'anywhere': 737,\n",
       " 'saturday': 738,\n",
       " 'barely': 739,\n",
       " 'superb': 740,\n",
       " 'weeks': 741,\n",
       " 'dessert': 742,\n",
       " 'bacon': 743,\n",
       " 'generous': 744,\n",
       " 'tip': 745,\n",
       " 'understand': 746,\n",
       " 'noodles': 747,\n",
       " 'services': 748,\n",
       " 'satisfied': 749,\n",
       " 'beers': 750,\n",
       " 'continue': 751,\n",
       " 'already': 752,\n",
       " 'crap': 753,\n",
       " 'literally': 754,\n",
       " 'pick': 755,\n",
       " 'may': 756,\n",
       " 'pancakes': 757,\n",
       " 'others': 758,\n",
       " 'spend': 759,\n",
       " 'shame': 760,\n",
       " 'arizona': 761,\n",
       " 'interesting': 762,\n",
       " 'past': 763,\n",
       " 'dogs': 764,\n",
       " 'mess': 765,\n",
       " 'street': 766,\n",
       " 'homemade': 767,\n",
       " 'months': 768,\n",
       " 'wash': 769,\n",
       " 'quiet': 770,\n",
       " 'friday': 771,\n",
       " 'serve': 772,\n",
       " 'goes': 773,\n",
       " 'under': 774,\n",
       " 'ready': 775,\n",
       " 'rather': 776,\n",
       " 'yourself': 777,\n",
       " 'sit': 778,\n",
       " 'knows': 779,\n",
       " 'started': 780,\n",
       " 'available': 781,\n",
       " 'pricing': 782,\n",
       " 'trust': 783,\n",
       " 'dive': 784,\n",
       " 'offered': 785,\n",
       " 'light': 786,\n",
       " 'tasteless': 787,\n",
       " 'salty': 788,\n",
       " 'school': 789,\n",
       " 'sick': 790,\n",
       " 'expect': 791,\n",
       " 'world': 792,\n",
       " 'feeling': 793,\n",
       " 'behind': 794,\n",
       " 'min': 795,\n",
       " 'sales': 796,\n",
       " 'son': 797,\n",
       " 'watch': 798,\n",
       " 'strip': 799,\n",
       " 'honestly': 800,\n",
       " 'month': 801,\n",
       " 'filling': 802,\n",
       " 'casual': 803,\n",
       " 'turned': 804,\n",
       " 'seated': 805,\n",
       " 'chain': 806,\n",
       " 'orders': 807,\n",
       " 'takes': 808,\n",
       " 'spent': 809,\n",
       " 'experienced': 810,\n",
       " 'mean': 811,\n",
       " 'hospital': 812,\n",
       " 'attention': 813,\n",
       " 'terrific': 814,\n",
       " 'hell': 815,\n",
       " 'bartenders': 816,\n",
       " 'chili': 817,\n",
       " 'weekend': 818,\n",
       " 'bagels': 819,\n",
       " 'given': 820,\n",
       " 'list': 821,\n",
       " 'boyfriend': 822,\n",
       " 'baked': 823,\n",
       " 'taken': 824,\n",
       " 'donuts': 825,\n",
       " 'tender': 826,\n",
       " 'finish': 827,\n",
       " 'birthday': 828,\n",
       " 'personable': 829,\n",
       " 'none': 830,\n",
       " 'show': 831,\n",
       " 'certainly': 832,\n",
       " 'sitting': 833,\n",
       " 'flavors': 834,\n",
       " 'welcome': 835,\n",
       " 'experiences': 836,\n",
       " 'rest': 837,\n",
       " 'facility': 838,\n",
       " 'daughter': 839,\n",
       " 'pedicure': 840,\n",
       " 'scottsdale': 841,\n",
       " 'thin': 842,\n",
       " 'tasting': 843,\n",
       " 'positive': 844,\n",
       " 'kitchen': 845,\n",
       " 'visiting': 846,\n",
       " 'option': 847,\n",
       " 'Negative': 848,\n",
       " 'girl': 849,\n",
       " 'downtown': 850,\n",
       " 'rating': 851,\n",
       " 'bite': 852,\n",
       " 'mom': 853,\n",
       " 'four': 854,\n",
       " 'obviously': 855,\n",
       " 'classic': 856,\n",
       " 'soggy': 857,\n",
       " 'deli': 858,\n",
       " 'delivered': 859,\n",
       " 'bother': 860,\n",
       " 'anyway': 861,\n",
       " 'dressing': 862,\n",
       " 'complete': 863,\n",
       " 'crowded': 864,\n",
       " 'ladies': 865,\n",
       " 'card': 866,\n",
       " 'starbucks': 867,\n",
       " 'mention': 868,\n",
       " 'haircut': 869,\n",
       " 'enjoyable': 870,\n",
       " 'grilled': 871,\n",
       " 'set': 872,\n",
       " 'save': 873,\n",
       " 'white': 874,\n",
       " 'knowledgable': 875,\n",
       " 'funny': 876,\n",
       " 'inexpensive': 877,\n",
       " 'workers': 878,\n",
       " 'early': 879,\n",
       " 'ended': 880,\n",
       " 'yeah': 881,\n",
       " 'chocolate': 882,\n",
       " 'future': 883,\n",
       " 'plain': 884,\n",
       " 'cozy': 885,\n",
       " 'salmon': 886,\n",
       " 'ribs': 887,\n",
       " 'overcooked': 888,\n",
       " 'pie': 889,\n",
       " 'products': 890,\n",
       " 'forward': 891,\n",
       " 'sign': 892,\n",
       " 'dentist': 893,\n",
       " 'onion': 894,\n",
       " 'mall': 895,\n",
       " 'game': 896,\n",
       " 'crowd': 897,\n",
       " 'bought': 898,\n",
       " 'pleasantly': 899,\n",
       " 'lack': 900,\n",
       " 'relaxing': 901,\n",
       " 'az': 902,\n",
       " 'bowl': 903,\n",
       " 'fix': 904,\n",
       " 'giving': 905,\n",
       " 'online': 906,\n",
       " 'might': 907,\n",
       " 'sent': 908,\n",
       " 'mins': 909,\n",
       " 'opinion': 910,\n",
       " 'veggies': 911,\n",
       " 'minute': 912,\n",
       " 'healthy': 913,\n",
       " 'lobster': 914,\n",
       " 'possible': 915,\n",
       " 'loud': 916,\n",
       " 'frozen': 917,\n",
       " 'unless': 918,\n",
       " 'organized': 919,\n",
       " 'sausage': 920,\n",
       " 'clearly': 921,\n",
       " 'fact': 922,\n",
       " 'park': 923,\n",
       " 'spring': 924,\n",
       " 'bathroom': 925,\n",
       " 'mind': 926,\n",
       " 'dollars': 927,\n",
       " 'immediately': 928,\n",
       " 'convenient': 929,\n",
       " 'greeted': 930,\n",
       " 'otherwise': 931,\n",
       " 'together': 932,\n",
       " 'anymore': 933,\n",
       " 'vet': 934,\n",
       " 'sides': 935,\n",
       " 'surprise': 936,\n",
       " 'sadly': 937,\n",
       " 'issue': 938,\n",
       " 'girls': 939,\n",
       " 'choose': 940,\n",
       " 'diner': 941,\n",
       " 'smell': 942,\n",
       " 'able': 943,\n",
       " 'miss': 944,\n",
       " 'class': 945,\n",
       " 'rate': 946,\n",
       " 'margaritas': 947,\n",
       " 'massage': 948,\n",
       " 'says': 949,\n",
       " 'lacking': 950,\n",
       " 'longer': 951,\n",
       " 'folks': 952,\n",
       " 'curry': 953,\n",
       " 'hand': 954,\n",
       " 'sour': 955,\n",
       " 'thorough': 956,\n",
       " 'apparently': 957,\n",
       " 'happened': 958,\n",
       " 'saw': 959,\n",
       " 'club': 960,\n",
       " 'entrees': 961,\n",
       " 'appreciate': 962,\n",
       " 'seasoned': 963,\n",
       " 'worked': 964,\n",
       " 'personal': 965,\n",
       " 'spectacular': 966,\n",
       " 'exactly': 967,\n",
       " 'expected': 968,\n",
       " 'checked': 969,\n",
       " 'write': 970,\n",
       " 'appetizers': 971,\n",
       " 'downhill': 972,\n",
       " 'foods': 973,\n",
       " 'weird': 974,\n",
       " 'juicy': 975,\n",
       " 'idea': 976,\n",
       " 'fairly': 977,\n",
       " 'stale': 978,\n",
       " 'vegetarian': 979,\n",
       " 'changed': 980,\n",
       " 'stores': 981,\n",
       " 'questions': 982,\n",
       " 'burritos': 983,\n",
       " 'cafe': 984,\n",
       " 'toast': 985,\n",
       " 'pieces': 986,\n",
       " 'color': 987,\n",
       " 'center': 988,\n",
       " 'damn': 989,\n",
       " 'sometimes': 990,\n",
       " 'hungry': 991,\n",
       " 'mac': 992,\n",
       " 'outdoor': 993,\n",
       " 'expectations': 994,\n",
       " 'single': 995,\n",
       " 'repair': 996,\n",
       " 'ugh': 997,\n",
       " 'decided': 998,\n",
       " 'five': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_style_classifier(data_loader, vocab_size, device):\n",
    "    classifier = StyleClassifier(vocab_size, 300, 128).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "    classifier.train()\n",
    "    for epoch in range(5):  # Train for a few epochs\n",
    "        total_loss = 0\n",
    "        for input_tokens, labels, _ in data_loader:  # Adjusted to unpack three values\n",
    "            input_tokens = input_tokens.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predictions = classifier(input_tokens)\n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/5, Loss: {total_loss / len(data_loader)}\")\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "def evaluate_style_transfer(data_loader, model, classifier, device):\n",
    "    model.eval()\n",
    "    classifier.eval()\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_tokens, labels, _ in data_loader:\n",
    "            input_tokens = input_tokens.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Get the reconstructed sentences\n",
    "            x_reconstructed, _, _, _ = model(input_tokens)\n",
    "            x_reconstructed = x_reconstructed.argmax(dim=-1)\n",
    "\n",
    "            # Predict the style of the reconstructed sentences\n",
    "            style_predictions = classifier(x_reconstructed)\n",
    "            style_labels = (style_predictions > 0.5).float()\n",
    "            \n",
    "            correct_predictions += (style_labels == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(f\"Style Transfer Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.09575918963146182\n",
      "Epoch 2/5, Loss: 0.05201591660841168\n",
      "Epoch 3/5, Loss: 0.038619662977903924\n",
      "Epoch 4/5, Loss: 0.029927782643674777\n",
      "Epoch 5/5, Loss: 0.02399632255074095\n",
      "Style Transfer Accuracy: 0.9780\n"
     ]
    }
   ],
   "source": [
    "classifier = train_style_classifier(data_loader, len(vocab), device)\n",
    "evaluate_style_transfer(data_loader_test, model_1, classifier, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
