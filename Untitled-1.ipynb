{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm  \n",
    "from dataloader import *\n",
    "from model import * \n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import nltk\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs, labels = zip(*batch)\n",
    "    max_length = max(len(seq) for seq in inputs)\n",
    "    \n",
    "    # Convert each sequence to a list, pad with 0, and convert to tensor\n",
    "    padded_inputs = [torch.cat([seq, torch.zeros(max_length - len(seq), dtype=torch.long)]) for seq in inputs]\n",
    "    lengths = [len(seq) for seq in inputs]\n",
    "    \n",
    "    return torch.stack(padded_inputs), torch.tensor(labels, dtype=torch.float), lengths\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "target_confidence = 0.8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 6926/6926 [05:34<00:00, 20.72batch/s, loss=0.618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 completed. Average Loss: 0.6183889831284934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 6926/6926 [05:37<00:00, 20.50batch/s, loss=0.229] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 completed. Average Loss: 0.22921297018383416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 6926/6926 [05:34<00:00, 20.71batch/s, loss=0.299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 completed. Average Loss: 0.2993834251228307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 6926/6926 [05:33<00:00, 20.77batch/s, loss=0.224] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 completed. Average Loss: 0.22419913678819037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 6926/6926 [05:29<00:00, 21.01batch/s, loss=0.616] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 completed. Average Loss: 0.6160696460356646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 6926/6926 [05:30<00:00, 20.96batch/s, loss=0.33]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 completed. Average Loss: 0.329525139434294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 6926/6926 [05:35<00:00, 20.62batch/s, loss=0.279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 completed. Average Loss: 0.2789108553194553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 6926/6926 [05:34<00:00, 20.73batch/s, loss=0.391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 completed. Average Loss: 0.3910796397221144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 6926/6926 [05:30<00:00, 20.93batch/s, loss=0.348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 completed. Average Loss: 0.34840153873824936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 6926/6926 [05:25<00:00, 21.27batch/s, loss=0.251]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 completed. Average Loss: 0.2513471563543881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    " \n",
    "data_dir = \"./data/sentiment_style_transfer/yelp\"\n",
    "vocab = build_vocab(data_dir)\n",
    "dataset = TextDataset(data_dir, vocab)\n",
    "data_loader = DataLoader(dataset, batch_size=64, collate_fn=collate_fn, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = StyleTransferModel(len(vocab), 300, 256, 16, 128).to(device)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm(data_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\")\n",
    "    \n",
    "    for input_tokens, labels, lengths in progress_bar:\n",
    "        input_tokens = input_tokens.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_reconstructed, style_mean, content_mean, s_prime = model(input_tokens, target_confidence)\n",
    "        style_logvar = torch.zeros_like(style_mean)\n",
    "        content_logvar = torch.zeros_like(content_mean)\n",
    "        loss = vae_loss(x_reconstructed, input_tokens, style_mean, style_logvar, content_mean, content_logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Update the progress bar with the current loss\n",
    "        progress_bar.set_postfix(loss=epoch_loss / (progress_bar.n + 1))\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} completed. Average Loss: {epoch_loss / len(data_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_complete.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74895/3363134432.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_1 = torch.load('model_complete.pth')\n"
     ]
    }
   ],
   "source": [
    "model_1 = torch.load('model_complete.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "class TextDatasetTest(Dataset):\n",
    "    def __init__(self, data_dir, vocab):\n",
    "        super(TextDatasetTest, self).__init__()\n",
    "        self.data = []\n",
    "        self.vocab = vocab\n",
    "\n",
    "        # Load data from the files\n",
    "        files = [\"sentiment.test.0\", \"sentiment.test.1\"]\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(data_dir, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    tokens = line.strip().split()\n",
    "                    label = 1 if filename.endswith('.1') else 0  # Binary label\n",
    "                    self.data.append((tokens, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens, label = self.data[idx]\n",
    "        token_ids = [self.vocab.get(token, self.vocab['<UNK>']) for token in tokens]\n",
    "        return torch.tensor(token_ids, dtype=torch.long), torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab(data_dir)\n",
    "dataset = TextDatasetTest(data_dir, vocab)\n",
    "data_loader_test = DataLoader(dataset, batch_size=64, collate_fn=collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/qik/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they', 'failed', 'to', 'tell', 'us', 'eating', 'in', 'the', 'bar', 'was', 'an', 'option', '.'] ['they', 'failed', 'to', 'tell', 'us', 'eating', 'in', 'the', 'bar', 'was', 'an', 'option', '.']\n",
      "['the', 'menudo', 'here', 'is', 'perfect', '.'] ['the', 'menudo', 'here', 'is', 'perfect', '.']\n",
      "['best', 'chicken', 'parmesan', 'i', 'have', 'ever', 'had', '.'] ['best', 'chicken', 'parmesan', 'i', 'have', 'ever', 'had', '.']\n",
      "['the', 'surly', 'older', 'waitress', 'was', 'a', 'huge', 'bummer', '.'] ['the', 'surly', 'older', 'waitress', 'was', 'a', 'huge', 'bummer', '.']\n",
      "['pricing', 'is', 'both', 'affordable', 'and', 'reasonable', '.'] ['pricing', 'is', 'both', 'affordable', 'and', 'reasonable', '.']\n",
      "['the', 'firecracker', 'shrimp', 'and', 'duck', 'is', 'also', 'always', 'a', 'winner', '.'] ['the', 'firecracker', 'shrimp', 'and', 'duck', 'is', 'also', 'always', 'a', 'winner', '.']\n",
      "['he', 'was', 'both', 'professional', 'and', 'courteous', '.'] ['he', 'was', 'both', 'professional', 'and', 'courteous', '.']\n",
      "['this', 'is', 'a', 'golf', 'course', 'that', 'is', 'tucked', 'away', 'it', 'is', 'in', 'great', 'condition', '.'] ['this', 'is', 'a', 'golf', 'course', 'that', 'is', 'tucked', 'away', 'it', 'is', 'in', 'great', 'condition', '.']\n",
      "['i', 'will', 'never', 'purchase', 'another', 'lv', 'bag', 'again', '.'] ['i', 'will', 'never', 'purchase', 'another', 'lv', 'bag', 'again', '.']\n",
      "['an', 'old', 'dude', 'did', 'my', 'pedicure', '.'] ['an', 'old', 'dude', 'did', 'my', 'pedicure', '.']\n",
      "Average BLEU Score: 0.9990\n"
     ]
    }
   ],
   "source": [
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to convert token IDs back to words using the vocabulary\n",
    "def tokens_to_words(token_ids, vocab):\n",
    "    inv_vocab = {v: k for k, v in vocab.items()}\n",
    "    return [inv_vocab.get(token_id, '<UNK>') for token_id in token_ids if token_id != 0]  # Exclude padding\n",
    "\n",
    "# Function to calculate BLEU score for a batch\n",
    "def calculate_bleu_score(data_loader, model, vocab, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_bleu_score = 0\n",
    "    num_sentences = 0\n",
    "    \n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for input_tokens, _, lengths in data_loader:\n",
    "            input_tokens = input_tokens.to(device)\n",
    "            x_reconstructed, _, _, _ = model(input_tokens)\n",
    "            x_reconstructed = x_reconstructed.argmax(dim=-1)  # Get the predicted token IDs\n",
    "\n",
    "            # Calculate BLEU score for each sentence\n",
    "            for i in range(len(input_tokens)):\n",
    "                original_sentence = tokens_to_words(input_tokens[i].tolist(), vocab)\n",
    "                reconstructed_sentence = tokens_to_words(x_reconstructed[i].tolist(), vocab)\n",
    "\n",
    "                counter += 1\n",
    "                if counter % 100 == 0:\n",
    "                    print(original_sentence, reconstructed_sentence)\n",
    "                # Calculate BLEU score\n",
    "                bleu_score = sentence_bleu([original_sentence], reconstructed_sentence)\n",
    "                total_bleu_score += bleu_score\n",
    "                num_sentences += 1\n",
    "\n",
    "    # Return the average BLEU score\n",
    "    return total_bleu_score / num_sentences if num_sentences > 0 else 0\n",
    "\n",
    "# Calculate the BLEU score\n",
    "bleu_score = calculate_bleu_score(data_loader_test, model_1, vocab, device)\n",
    "print(f\"Average BLEU Score: {bleu_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence:  the green enchiladas were ok but not great .\n",
      "Reconstructed Sentence:  the green enchiladas were ok but not great .\n",
      "\n",
      "Original Sentence:  however , this experience went pretty smooth .\n",
      "Reconstructed Sentence:  however , this experience went pretty smooth .\n",
      "\n",
      "Original Sentence:  giving an extra star for customer service .\n",
      "Reconstructed Sentence:  giving an extra star for customer service .\n",
      "\n",
      "Original Sentence:  the tow package is not an issue either .\n",
      "Reconstructed Sentence:  the tow package is not an issue either .\n",
      "\n",
      "Original Sentence:  the grounds are always very clean .\n",
      "Reconstructed Sentence:  the grounds are always very clean .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def tokens_to_words(token_ids, vocab):\n",
    "    inv_vocab = {v: k for k, v in vocab.items()}\n",
    "    return [inv_vocab.get(token_id, '<UNK>') for token_id in token_ids if token_id != 0]  # Exclude padding\n",
    "\n",
    "# Inspect some sentences from the data loader\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for input_tokens, _, lengths in data_loader_test:\n",
    "        input_tokens = input_tokens.to(device)\n",
    "        x_reconstructed, _, _, _ = model_1(input_tokens)\n",
    "        x_reconstructed = x_reconstructed.argmax(dim=-1)  # Get the predicted token IDs\n",
    "\n",
    "        # Print a few input and output sentences\n",
    "        for i in range(5):  # Print 5 examples\n",
    "            original_sentence = tokens_to_words(input_tokens[i].tolist(), vocab)\n",
    "            reconstructed_sentence = tokens_to_words(x_reconstructed[i].tolist(), vocab)\n",
    "\n",
    "            print(\"Original Sentence: \", \" \".join(original_sentence))\n",
    "            print(\"Reconstructed Sentence: \", \" \".join(reconstructed_sentence))\n",
    "            print()\n",
    "\n",
    "        break  # Only inspect the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
